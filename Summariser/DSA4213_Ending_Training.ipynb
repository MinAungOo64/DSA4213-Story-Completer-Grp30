{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f01f44",
   "metadata": {},
   "source": [
    "# Finetuning model for Ending summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e62adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to d:\\Keven(Work)\\dsa4213\\final\n",
      "[nltk_data]     project\\venv\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     d:\\Keven(Work)\\dsa4213\\final project\\venv\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     d:\\Keven(Work)\\dsa4213\\final project\\venv\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n",
    "from bert_score import score\n",
    "import evaluate\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "# Make sure the required NLTK data packages are available\n",
    "# Dynamically construct NLTK data directory relative to current working directory\n",
    "nltk_data_dir = os.path.join(os.getcwd(), \"venv\", \"nltk_data\")\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(nltk_data_dir, exist_ok=True)\n",
    "\n",
    "nltk.download(\"punkt\", download_dir=nltk_data_dir)\n",
    "nltk.download('punkt_tab', download_dir=nltk_data_dir)\n",
    "nltk.download(\"stopwords\", download_dir=nltk_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3e9e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "def set_seed(seed=4213):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(4213)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf5599fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "# ==============================\n",
    "TRAIN_FILE = \"stories_with_outlines_first3000.jsonl\"\n",
    "OUTPUT_DIR = \"./Ending-summariser-LoRA-v2\"\n",
    "BASE_MODEL = \"t5-small\"\n",
    "BASE_MODEL2 = \"google/flan-t5-base\"\n",
    "USE_LORA = True\n",
    "MAX_INPUT_LENGTH = 512\n",
    "MAX_TARGET_LENGTH = 128\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8685930",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c574d19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading each event dataset: stories_with_outlines_first3000.jsonl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Extract the ending for this text:\\nOnce upon a time, in a warm and sunny place, there was a big pit. A little boy named Tom liked to play near the pit. One day, Tom lost his red ball. He was very sad.\\nTom asked his friend, Sam, to help him search for the ball. They looked high and low, but they could not find the ball. Tom said, \"I think my ball fell into the pit.\"\\nSam and Tom went close to the pit. They were scared, but they wanted to find the red ball. They looked into the pit, but it was too dark to see. Tom said, \"We must go in and search for my ball.\"\\nThey went into the pit to search. It was dark and scary. They could not find the ball. They tried to get out, but the pit was too deep. Tom and Sam were stuck in the pit. They called for help, but no one could hear them. They were sad and scared, and they never got out of the pit.',\n",
       "  'response': 'Tom and Sam remain trapped in the pit, feeling hopeless and frightened.'},\n",
       " {'instruction': 'Extract the ending for this text:\\nTom and Lily were playing with their toys in the living room. They liked to build towers and bridges with their blocks and cars. Tom was very proud of his tall tower. He wanted to make it even taller, so he reached for more blocks.\\n\"Tom, can I have some blocks too?\" Lily asked. She wanted to make a bridge for her cars.\\n\"No, these are mine. Go find your own,\" Tom said. He did not want to share with his sister. He pulled the blocks closer to him.\\nLily felt sad and angry. She did not think Tom was being nice. She looked at his tower and had an idea. She decided to pull one of the blocks at the bottom of the tower.\\nSuddenly, the tower fell down with a loud crash. All the blocks and cars scattered on the floor. Tom and Lily were shocked. They felt the floor shake and heard a rumble. It was an earthquake!\\n\"Mommy! Daddy!\" they cried. They were scared and ran to their parents, who were in the kitchen.\\n\"Are you okay, kids?\" Mommy asked. She hugged them and checked if they were hurt.\\n\"We\\'re okay, Mommy. But our toys are broken,\" Lily said.\\n\"I\\'m sorry, Lily. But toys are not important. You are important. We are safe and together. That\\'s what matters,\" Mommy said.\\nTom felt sorry for what he did. He realized he was selfish and mean to his sister. He saw how scared she was during the earthquake. He wanted to make her happy.\\n\"Lily, I\\'m sorry I did not share with you. You can have all the blocks you want. I love you, sister,\" Tom said.\\nLily smiled and hugged him. She forgave him and thanked him. She loved him too.\\nThey went back to the living room and cleaned up their toys. They decided to build something together. They made a big house with a garden and a fence. They put their cars and dolls inside. They were happy and proud of their work.\\nMommy and Daddy came to see their house. They praised them and gave them a treat. It was a lemon cake. It was sour, but they liked it. They learned that sharing is caring, and that family is sweet.',\n",
       "  'response': 'Tom and Lily realize the importance of sharing and family after their adventure.'},\n",
       " {'instruction': 'Extract the ending for this text:\\nOnce upon a time there was a little girl named Lucy. She loved to go to the store to buy sweets with her mom and dad. On this special day, Lucy entered the store with her mom and dad, feeling so excited.\\nAs they were looking around, Lucy noticed a little girl playing with a toy in the corner of the store. She gasped in excitement and ran towards her. Lucy asked if she could play too but the little girl said no. She was rather grumpy and was not in the mood to play.\\nLucy\\'s mom saw what was going on and told Lucy, \"Let\\'s try to be peaceful and kind to her. Have patience and understanding. Together, you can both be happy!\"\\nSo, Lucy smiled at the girl and said, \"Can we play together?\" The little girl softened and smiled back. She agreed to share the toy and even let Lucy have a turn first.\\nLucy and the little girl played together happily. In the end, they both learnt an important lesson: be peaceful, kind, and understanding when faced with a conflict. And that is why Lucy and the little girl became great friends.',\n",
       "  'response': 'Lucy and the little girl become great friends after learning to be peaceful and kind.'},\n",
       " {'instruction': 'Extract the ending for this text:\\nOne morning, a cat named Tom woke up. He felt happy because the sun was shining. Tom wanted to start his day, so he did a big stretch. He stretched his legs, his back, and his tail. It felt easy and good.\\nTom went outside to play. He saw his friend, a dog named Max. Max was also stretching in the morning sun. They both felt very happy. They decided to play together and have fun all day.\\nAt the end of the day, Tom and Max were tired. They had played all day and had lots of fun. They said goodbye to each other and went to their homes. Before going to sleep, they both did another easy stretch. Tom knew that tomorrow would be another happy morning.',\n",
       "  'response': 'Tom and Max end their day content, anticipating more joy tomorrow.'},\n",
       " {'instruction': 'Extract the ending for this text:\\nLily and Tom were twins who liked to decorate things. They had a big box of crayons, stickers, and glitter. One day, they found a shiny copper pot in the kitchen. It was Mom\\'s pot, but she was not home. Lily and Tom wanted to make it more pretty.\\nThey took the pot to their room and put it on the floor. They opened their box of crayons, stickers, and glitter. They started to draw and stick and sprinkle on the pot. They made colorful shapes and patterns. They thought the pot looked very nice.\\nBut they were clumsy. They did not see that they also made a big mess. They spilled glitter on the floor and the bed. They stuck stickers on the wall and the door. They drew crayons on the window and the dresser. They did not hear Mom come home.\\nMom saw the mess in the kitchen. She saw the glitter, the stickers, and the crayons. She was angry. She followed the trail to their room. She saw the pot. She saw the floor, the bed, the wall, the door, the window, and the dresser. She was very angry.\\nShe said, \"Lily and Tom, what did you do? You ruined my pot and my room. You are very naughty. You have to clean up everything. And you have to say sorry.\"\\nLily and Tom were scared. They did not mean to make Mom angry. They only wanted to decorate the pot. They said, \"Sorry, Mom. We love you. We will clean up. Please don\\'t be mad.\"\\nMom sighed. She was still angry, but she also loved them. She said, \"I love you too, but you have to be careful. You can\\'t touch my things without asking. And you can\\'t make a mess like this. You have to learn to be more tidy and respectful.\"\\nLily and Tom nodded. They hugged Mom and said, \"We will, Mom. We will.\" They took a broom, a dustpan, and a cloth. They started to clean up their mess. They hoped Mom would forgive them. They learned their lesson. They would not decorate Mom\\'s pot again.',\n",
       "  'response': 'Lily and Tom clean up their mess and promise to be more careful in the future.'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in raw data\n",
    "\n",
    "print(f\"Loading each event dataset: {TRAIN_FILE}\")\n",
    "# Read all lines as JSON\n",
    "raw_data = []\n",
    "with open(TRAIN_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        each_line = json.loads(line)\n",
    "        # extract story text and reformat input\n",
    "        story = each_line['story']\n",
    "        prompt = \"Extract the ending for this text:\\n\" \n",
    "        final_input = prompt + story\n",
    "        # extract outline details: ending\n",
    "        outline = each_line['outline']\n",
    "        ending = outline['ending'].get('summary')\n",
    "\n",
    "        # append to dataset\n",
    "        raw_data.append({\"instruction\": final_input, \"response\": ending})\n",
    "\n",
    "raw_data[:5]  # preview first 5 entries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d06ff040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'response'],\n",
       "        num_rows: 2970\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'response'],\n",
       "        num_rows: 30\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_list(raw_data)\n",
    "dataset = dataset.train_test_split(test_size=0.01)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceb8c9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model: t5-small\n"
     ]
    }
   ],
   "source": [
    "# Prepare tokenizer and model\n",
    "print(f\"Loading base model: {BASE_MODEL}\")\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(BASE_MODEL).to(DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07e91174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing dataset: 100%|██████████| 2970/2970 [00:02<00:00, 1146.27 examples/s]\n",
      "Tokenizing dataset: 100%|██████████| 30/30 [00:00<00:00, 999.93 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_function(batch):\n",
    "    model_inputs = tokenizer(\n",
    "        batch[\"instruction\"],\n",
    "        max_length=MAX_INPUT_LENGTH,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        text_target=batch[\"response\"],\n",
    "        max_length=MAX_TARGET_LENGTH,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        )  \n",
    "    # Replace pad token IDs with -100 so they’re ignored in cross-entropy loss\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(token if token != tokenizer.pad_token_id else -100) for token in label]\n",
    "        for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_dataset = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"instruction\", \"response\"],\n",
    "    desc=\"Tokenizing dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2334851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Story:\n",
      "Extract the ending for this text:\n",
      "Once there was a very curious little kitten. One day, she was walking when she heard a strange noise. She looked around but she couldn't find where the noise was coming from. Suddenly, she saw a boy stretching on the grass. The curious little kitten went closer to take a look.\n",
      "The boy noticed her and said, \"Hi little kitten! How are you?\" The little kitten meowed in reply.\n",
      "The boy continued, \"Let me tell you something important. Whenever we are feeling down or in bad mood, we can try stretching. It will help us feel better.\" Then the boy demonstrated some stretches.\n",
      "The little kitten was amazed! She copied the boy and began stretching. Suddenly, she felt much better.\n",
      "The little kitten said goodbye to the boy with a meow. She understood the moral of the story: when you are feeling down, try stretching and you will be able to feel better too!\n",
      "--------------------------------------------------------------------------------\n",
      "Expected ending:\n",
      "The kitten learns that stretching can help improve one's mood.\n",
      "--------------------------------------------------------------------------------\n",
      "Model Output ending:\n",
      ": a strange noise. She copied the boy and began stretching. Suddenly, she felt much better. She copied the boy and began stretching. Suddenly, she felt much better. The little kitten said goodbye to the boy with a meow.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test current model with zero shot inference\n",
    "from torch import no_grad\n",
    "\n",
    "# use one example from test set\n",
    "story = dataset['test'][22][\"instruction\"]\n",
    "ending = dataset['test'][22][\"response\"]\n",
    "\n",
    "# Tokenise input\n",
    "inputs = tokenizer(story, return_tensors=\"pt\", max_length=MAX_INPUT_LENGTH, truncation=True).to(DEVICE)\n",
    "# Generate output and decode\n",
    "with no_grad():\n",
    "    outputs = base_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=MAX_TARGET_LENGTH,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "base_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "dashline = \"-\" * 80\n",
    "print(dashline)\n",
    "print(\"Story:\")\n",
    "print(story)\n",
    "print(dashline)\n",
    "print(\"Expected ending:\")  \n",
    "print(ending)\n",
    "print(dashline)\n",
    "print(\"Model Output ending:\")\n",
    "print(base_output)\n",
    "print(dashline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0328e9da",
   "metadata": {},
   "source": [
    "# PEFT model using LoRA\n",
    "(skip the cells in this section if not finetuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "500ec677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA adapter for lightweight fine-tuning...\n",
      "trainable params: 1,179,648 || all params: 61,686,272 || trainable%: 1.9123\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# LoRA configuration\n",
    "if USE_LORA:\n",
    "    print(\"Applying LoRA adapter for lightweight fine-tuning...\")\n",
    "    lora_config = LoraConfig(\n",
    "        r=32,\n",
    "        lora_alpha=128,\n",
    "        target_modules=[\"q\", \"v\"],\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"SEQ_2_SEQ_LM\",\n",
    "    )\n",
    "lora_model = get_peft_model(base_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "lora_model = lora_model.to(DEVICE)\n",
    "\n",
    "# PEFT Training configuration\n",
    "peft_training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    auto_find_batch_size=True,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=3e-5,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    predict_with_generate=True,\n",
    "    report_to=\"none\",  # disable wandb/tensorboard\n",
    "    save_strategy=\"steps\",  \n",
    "    save_steps=50,          \n",
    "    save_total_limit=3,     \n",
    "    logging_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=lora_model\n",
    ")\n",
    "\n",
    "# PEFT Trainer setup\n",
    "peft_trainer = Trainer(  \n",
    "    model=lora_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66b87494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "No existing checkpoint found — starting fresh training.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='465' max='465' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [465/465 04:52, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>2.943900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>2.463100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>2.298400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>372</td>\n",
       "      <td>2.238400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>2.203500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving LoRA fine-tuned model to ./Ending-summariser-LoRA-v2\n"
     ]
    }
   ],
   "source": [
    "# Initiate training\n",
    "\n",
    "print(\"Starting training...\")\n",
    "# Resume only if checkpoint exists\n",
    "resume_checkpoint = None\n",
    "last_checkpoint_dir = os.path.join(OUTPUT_DIR, \"checkpoint-last\")\n",
    "if os.path.isdir(last_checkpoint_dir):\n",
    "    resume_checkpoint = last_checkpoint_dir\n",
    "    print(f\"Resuming from checkpoint: {resume_checkpoint}\")\n",
    "else:\n",
    "    print(\"No existing checkpoint found — starting fresh training.\")\n",
    "\n",
    "# Else start training\n",
    "peft_trainer.train(resume_from_checkpoint=resume_checkpoint)\n",
    "\n",
    "# Save the final model with training logs\n",
    "print(f\"Saving LoRA fine-tuned model to {OUTPUT_DIR}\")\n",
    "lora_model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "peft_trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e10ee63",
   "metadata": {},
   "source": [
    "# Models Testing and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b402c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded t5-small on device: cuda\n",
      "Loaded google/flan-t5-base on device: cuda\n",
      "Loaded ./Ending-summariser-LoRA-v1 on device: cuda\n",
      "Loaded ./Ending-summariser-LoRA-v2 on device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Now we can test and compare the models on the same example\n",
    "def load_model_for_inference(directory, device=DEVICE):\n",
    "    if directory==BASE_MODEL or BASE_MODEL2:\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(directory)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(directory)\n",
    "    else:\n",
    "        config = PeftConfig.from_pretrained(directory)\n",
    "        base_model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path)\n",
    "        model = PeftModel.from_pretrained(base_model, directory)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "    model = model.to(device)\n",
    "    model.eval()  # ensure inference mode\n",
    "    print(f\"Loaded {directory} on device: {device}\")\n",
    "    return model, tokenizer\n",
    "\n",
    "# function to generate outputs\n",
    "def generate_output(text_input, model, tokenizer, device=DEVICE):\n",
    "    # generate input\n",
    "    inputs = tokenizer(text_input, return_tensors=\"pt\").to(device)\n",
    "    # then generate output\n",
    "    with torch.inference_mode():\n",
    "        output = tokenizer.decode(\n",
    "        model.generate(**inputs, max_new_tokens=MAX_TARGET_LENGTH)[0],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    return output\n",
    "\n",
    "t5_small, t5s_tokenizer = load_model_for_inference(BASE_MODEL)\n",
    "flan_t5, ft5_tokenizer = load_model_for_inference(BASE_MODEL2)\n",
    "lora_v1, lv1_tokenizer = load_model_for_inference(\"./Ending-summariser-LoRA-v1\")\n",
    "lora_v2, lv2_tokenizer = load_model_for_inference(\"./Ending-summariser-LoRA-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43ea28cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "Extract the ending for this text:\n",
      "Once there was a very curious little kitten. One day, she was walking when she heard a strange noise. She looked around but she couldn't find where the noise was coming from. Suddenly, she saw a boy stretching on the grass. The curious little kitten went closer to take a look.\n",
      "The boy noticed her and said, \"Hi little kitten! How are you?\" The little kitten meowed in reply.\n",
      "The boy continued, \"Let me tell you something important. Whenever we are feeling down or in bad mood, we can try stretching. It will help us feel better.\" Then the boy demonstrated some stretches.\n",
      "The little kitten was amazed! She copied the boy and began stretching. Suddenly, she felt much better.\n",
      "The little kitten said goodbye to the boy with a meow. She understood the moral of the story: when you are feeling down, try stretching and you will be able to feel better too!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Expected summary:\n",
      "The kitten learns that stretching can help improve one's mood.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "t5_small Output summary:\n",
      ": the boy. the boy and began stretching. Suddenly, she felt much better. The little kitten said goodbye to the boy with a meow.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "flan_t5 Output summary:\n",
      "The little kitten was happy.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lora_v1 Output summary:\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lora_v2 Output summary:\n",
      "The little kitten's journey of stretching helps her feel better.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display summaries\n",
    "print(\"-\" * 100)\n",
    "print(\"Actual Text:\")\n",
    "print(story)\n",
    "print(\"-\" * 100)\n",
    "print(\"Expected summary:\")  \n",
    "print(ending)\n",
    "print(\"-\" * 100)\n",
    "print(\"t5_small Output summary:\")\n",
    "print(generate_output(story, t5_small, t5s_tokenizer))\n",
    "print(\"-\" * 100)\n",
    "print(\"flan_t5 Output summary:\")\n",
    "print(generate_output(story, flan_t5, ft5_tokenizer))\n",
    "print(\"-\" * 100)\n",
    "print(\"lora_v1 Output summary:\")\n",
    "print(generate_output(story, lora_v1, lv1_tokenizer))\n",
    "print(\"-\" * 100)\n",
    "print(\"lora_v2 Output summary:\")\n",
    "print(generate_output(story, lora_v2, lv2_tokenizer))\n",
    "print(\"-\" * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556bb099",
   "metadata": {},
   "source": [
    "# Evaluation using ROGUE + BERT scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e14dd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n"
     ]
    }
   ],
   "source": [
    "# prepare the eval dataset to be used for rouge evaluation\n",
    "original_summaries = []\n",
    "base_model1_predictions = []\n",
    "base_model2_predictions = []\n",
    "lora1_model_predictions = []\n",
    "lora2_model_predictions = []\n",
    "\n",
    "print(\"Generating predictions...\")\n",
    "for item in dataset['test']:    # replace test_subset with eval_data\n",
    "    # original summary list\n",
    "    original_summaries.append(item[\"response\"])\n",
    "    # predictions\n",
    "    base1_output = generate_output(item[\"instruction\"], t5_small, t5s_tokenizer)\n",
    "    base_model1_predictions.append(base1_output)\n",
    "    base2_output = generate_output(item[\"instruction\"], flan_t5, ft5_tokenizer)\n",
    "    base_model2_predictions.append(base2_output)\n",
    "    lora1_output = generate_output(item[\"instruction\"], lora_v1, lv1_tokenizer)\n",
    "    lora1_model_predictions.append(lora1_output)\n",
    "    lora2_output = generate_output(item[\"instruction\"], lora_v2, lv2_tokenizer)\n",
    "    lora2_model_predictions.append(lora2_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39594ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Summary</th>\n",
       "      <th>t5-small Prediction</th>\n",
       "      <th>flan-t5-base Prediction</th>\n",
       "      <th>LoRA-v1 Model Prediction</th>\n",
       "      <th>LoRA-v2 Model Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The man's perseverance and the advice from his...</td>\n",
       "      <td>: the wall. the wall. He was so tired he could...</td>\n",
       "      <td>The man was proud of his work.</td>\n",
       "      <td>True</td>\n",
       "      <td>The man's strength and enduring the tiredness ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom and his friends experience joy from both t...</td>\n",
       "      <td>:: Tom and his friends saved the cat. They wer...</td>\n",
       "      <td>Tom and his friends made a film together.</td>\n",
       "      <td>True</td>\n",
       "      <td>Tom and his friends saved the cat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mia's passion for painting grows, inspiring he...</td>\n",
       "      <td>Mia was happy with her original painting. She ...</td>\n",
       "      <td>Mia was happy with her painting.</td>\n",
       "      <td>True</td>\n",
       "      <td>Mia's life has changed, making the world a mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The family leaves the ranch happily with their...</td>\n",
       "      <td>,, and they went to an expensive ranch in the ...</td>\n",
       "      <td>The family went home happy.</td>\n",
       "      <td>True</td>\n",
       "      <td>The family and the Mom enjoy their time here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lily commits to helping others and being kind ...</td>\n",
       "      <td>:: her mom was making a thin mattress for her ...</td>\n",
       "      <td>Lily and her mom were proud of their work.</td>\n",
       "      <td>True</td>\n",
       "      <td>Lily and her mom learned that helping others a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Original Summary  \\\n",
       "0  The man's perseverance and the advice from his...   \n",
       "1  Tom and his friends experience joy from both t...   \n",
       "2  Mia's passion for painting grows, inspiring he...   \n",
       "3  The family leaves the ranch happily with their...   \n",
       "4  Lily commits to helping others and being kind ...   \n",
       "\n",
       "                                 t5-small Prediction  \\\n",
       "0  : the wall. the wall. He was so tired he could...   \n",
       "1  :: Tom and his friends saved the cat. They wer...   \n",
       "2  Mia was happy with her original painting. She ...   \n",
       "3  ,, and they went to an expensive ranch in the ...   \n",
       "4  :: her mom was making a thin mattress for her ...   \n",
       "\n",
       "                      flan-t5-base Prediction LoRA-v1 Model Prediction  \\\n",
       "0              The man was proud of his work.                     True   \n",
       "1   Tom and his friends made a film together.                     True   \n",
       "2            Mia was happy with her painting.                     True   \n",
       "3                 The family went home happy.                     True   \n",
       "4  Lily and her mom were proud of their work.                     True   \n",
       "\n",
       "                            LoRA-v2 Model Prediction  \n",
       "0  The man's strength and enduring the tiredness ...  \n",
       "1                 Tom and his friends saved the cat.  \n",
       "2  Mia's life has changed, making the world a mor...  \n",
       "3      The family and the Mom enjoy their time here.  \n",
       "4  Lily and her mom learned that helping others a...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine into dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"Original Summary\": original_summaries,\n",
    "    \"t5-small Prediction\": base_model1_predictions,\n",
    "    \"flan-t5-base Prediction\": base_model2_predictions,\n",
    "    \"LoRA-v1 Model Prediction\": lora1_model_predictions,\n",
    "    \"LoRA-v2 Model Prediction\": lora2_model_predictions\n",
    "})\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc4222a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 6.14kB [00:00, 6.15MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Perform ROUGE evaluation\n",
    "def compute_rouge_score(predictions, references):\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    results = rouge.compute(\n",
    "        predictions=predictions, \n",
    "        references=references,\n",
    "        use_aggregator=True,\n",
    "        use_stemmer=True,\n",
    "    )\n",
    "    return results\n",
    "\n",
    "# Clean text for fair comparison\n",
    "original_summaries = [s.strip().lower() for s in original_summaries]\n",
    "base_model1_predictions = [p.strip().lower() for p in base_model1_predictions]\n",
    "base_model2_predictions = [p.strip().lower() for p in base_model2_predictions]\n",
    "lora_model1_predictions = [p.strip().lower() for p in lora1_model_predictions]\n",
    "lora_model2_predictions = [p.strip().lower() for p in lora2_model_predictions]\n",
    "\n",
    "# Compute ROUGE scores\n",
    "base_model1_results = compute_rouge_score(base_model1_predictions, original_summaries)\n",
    "base_model2_results = compute_rouge_score(base_model2_predictions, original_summaries)\n",
    "lora1_model_results = compute_rouge_score(lora1_model_predictions, original_summaries)\n",
    "lora2_model_results = compute_rouge_score(lora2_model_predictions, original_summaries)\n",
    "\n",
    "all_results = {\n",
    "    \"t5-small Model\": base_model1_results,\n",
    "    \"flan-t5-base Model\": base_model2_results,\n",
    "    \"LoRA-v1 Model\": lora1_model_results,\n",
    "    \"LoRA-v2 Model\": lora2_model_results\n",
    "}\n",
    "\n",
    "# Compare relative percentage differences in rouge scores over base model\n",
    "def display_percentage_difference(base_results, new_results, model_name):\n",
    "    print(f\"Relative Percentage Differences in ROUGE scores for {model_name} over Base Model:\")\n",
    "    for key in base_results.keys():\n",
    "        base_score = base_results[key] * 100  # convert to percentage\n",
    "        new_score = new_results[key] * 100  # convert to percentage\n",
    "        relative_diff = ((new_score - base_score) / base_score) * 100\n",
    "        print(f\"{key}: {relative_diff:.2f}%\")\n",
    "    print(dashline)\n",
    "\n",
    "#display_percentage_difference(base_model_results, lora1_model_results, \"LoRA-v1 Model\")\n",
    "#display_percentage_difference(base_model_results, lora2_model_results, \"LoRA-v2 Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33f344ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE scores for various models against actual endings:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t5-small Model</th>\n",
       "      <td>0.207889</td>\n",
       "      <td>0.060395</td>\n",
       "      <td>0.165291</td>\n",
       "      <td>0.165990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan-t5-base Model</th>\n",
       "      <td>0.283650</td>\n",
       "      <td>0.083504</td>\n",
       "      <td>0.242818</td>\n",
       "      <td>0.242056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA-v1 Model</th>\n",
       "      <td>0.112341</td>\n",
       "      <td>0.035808</td>\n",
       "      <td>0.099764</td>\n",
       "      <td>0.098289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA-v2 Model</th>\n",
       "      <td>0.385434</td>\n",
       "      <td>0.161655</td>\n",
       "      <td>0.361942</td>\n",
       "      <td>0.361789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      rouge1    rouge2    rougeL  rougeLsum\n",
       "t5-small Model      0.207889  0.060395  0.165291   0.165990\n",
       "flan-t5-base Model  0.283650  0.083504  0.242818   0.242056\n",
       "LoRA-v1 Model       0.112341  0.035808  0.099764   0.098289\n",
       "LoRA-v2 Model       0.385434  0.161655  0.361942   0.361789"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ROUGE scores for various models against actual endings:\")\n",
    "results_df = pd.DataFrame.from_dict(all_results, orient='index')\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3798a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot visuals\n",
    "keys = list(base_model1_results.keys())\n",
    "base1_vals = [base_model1_results[k] * 100 for k in keys]\n",
    "base2_vals = [base_model2_results[k] * 100 for k in keys]\n",
    "lora1_vals = [lora1_model_results[k] * 100 for k in keys]\n",
    "lora2_vals = [lora2_model_results[k] * 100 for k in keys]\n",
    "\n",
    "x = np.arange(len(keys))  # the label locations\n",
    "width = 0.2             # width of each bar\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.bar(x - width*2, base1_vals, width, label='Base T5-small')\n",
    "plt.bar(x - width, base2_vals, width, label='Flan-T5-base')\n",
    "plt.bar(x , lora1_vals, width, label='LoRA Fine-Tuned v1')\n",
    "plt.bar(x + width, lora2_vals, width, label='LoRA Fine-Tuned v2')\n",
    "\n",
    "plt.xticks(x, keys)\n",
    "plt.title('ROUGE Score Comparison')\n",
    "plt.ylabel('Score (%)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dda6a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 90.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.66 seconds, 45.58 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 99.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.16 seconds, 188.48 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 111.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.56 seconds, 53.80 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 111.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.21 seconds, 140.73 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Now evaluate using BERT score\n",
    "def compute_bert_score(predictions, references):\n",
    "    P, R, F1 = score(predictions, references, model_type=\"roberta-large\" ,lang=\"en\", verbose=True)\n",
    "    return {\n",
    "        \"precision\": P.mean().item(),\n",
    "        \"recall\": R.mean().item(),\n",
    "        \"f1\": F1.mean().item()\n",
    "    }\n",
    "\n",
    "base_model1_bert = compute_bert_score(base_model1_predictions, original_summaries)\n",
    "base_model2_bert = compute_bert_score(base_model2_predictions, original_summaries)\n",
    "lora1_model_bert = compute_bert_score(lora1_model_predictions, original_summaries)\n",
    "lora2_model_bert = compute_bert_score(lora2_model_predictions, original_summaries)\n",
    "\n",
    "all_berts = {\n",
    "    \"t5-small Model\": base_model1_bert,\n",
    "    \"flan-t5-base Model\": base_model2_bert,\n",
    "    \"LoRA-v1 Model\": lora1_model_bert,\n",
    "    \"LoRA-v2 Model\": lora2_model_bert\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9f1c2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT scores for predictions against actual endings:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t5-small Model</th>\n",
       "      <td>0.844834</td>\n",
       "      <td>0.880060</td>\n",
       "      <td>0.861993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan-t5-base Model</th>\n",
       "      <td>0.914909</td>\n",
       "      <td>0.883589</td>\n",
       "      <td>0.898881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA-v1 Model</th>\n",
       "      <td>0.853747</td>\n",
       "      <td>0.839858</td>\n",
       "      <td>0.846636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA-v2 Model</th>\n",
       "      <td>0.911584</td>\n",
       "      <td>0.895932</td>\n",
       "      <td>0.903605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    precision    recall        f1\n",
       "t5-small Model       0.844834  0.880060  0.861993\n",
       "flan-t5-base Model   0.914909  0.883589  0.898881\n",
       "LoRA-v1 Model        0.853747  0.839858  0.846636\n",
       "LoRA-v2 Model        0.911584  0.895932  0.903605"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"BERT scores for predictions against actual endings:\")\n",
    "bert_df = pd.DataFrame.from_dict(all_berts, orient='index')\n",
    "bert_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
