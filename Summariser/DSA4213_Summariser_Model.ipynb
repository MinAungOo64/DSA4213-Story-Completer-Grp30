{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1910bad1",
   "metadata": {},
   "source": [
    "# Notebook to test story JSON outliner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d545ee16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Keven(Work)\\dsa4213\\final project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to d:\\Keven(Work)\\dsa4213\\final\n",
      "[nltk_data]     project\\venv\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     d:\\Keven(Work)\\dsa4213\\final project\\venv\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     d:\\Keven(Work)\\dsa4213\\final project\\venv\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import torch\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    ")\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "# Make sure the required NLTK data packages are available\n",
    "# Dynamically construct NLTK data directory relative to current working directory\n",
    "nltk_data_dir = os.path.join(os.getcwd(), \"venv\", \"nltk_data\")\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(nltk_data_dir, exist_ok=True)\n",
    "\n",
    "nltk.download(\"punkt\", download_dir=nltk_data_dir)\n",
    "nltk.download('punkt_tab', download_dir=nltk_data_dir)\n",
    "nltk.download(\"stopwords\", download_dir=nltk_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4470fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "# ==============================\n",
    "DATA_FILE = \"stories_with_outlines_first3000.jsonl\"\n",
    "EVENT_MODEL = \"./Event-summariser-LoRA-v1\"\n",
    "ENDING_MODEL = \"./Ending-summariser-LoRA-v2\"\n",
    "QA_MODEL = \"./QA-LoRA-v2\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61f724f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading event summariser model: ./Event-summariser-LoRA-v1\n",
      "Loading ending summariser model: ./Ending-summariser-LoRA-v2\n",
      "Loading QA model: ./QA-LoRA-v2\n"
     ]
    }
   ],
   "source": [
    "# Prepare tokenizers and models\n",
    "print(f\"Loading event summariser model: {EVENT_MODEL}\")\n",
    "event_model = AutoModelForSeq2SeqLM.from_pretrained(EVENT_MODEL).to(DEVICE)\n",
    "event_tokenizer = AutoTokenizer.from_pretrained(EVENT_MODEL)\n",
    "print(f\"Loading ending summariser model: {ENDING_MODEL}\")\n",
    "ending_model = AutoModelForSeq2SeqLM.from_pretrained(ENDING_MODEL).to(DEVICE)\n",
    "ending_tokenizer = AutoTokenizer.from_pretrained(ENDING_MODEL)\n",
    "print(f\"Loading QA model: {QA_MODEL}\")\n",
    "qa_model = AutoModelForSeq2SeqLM.from_pretrained(QA_MODEL).to(DEVICE)\n",
    "qa_tokenizer = AutoTokenizer.from_pretrained(QA_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8685930",
   "metadata": {},
   "source": [
    "# Data Preview\n",
    "(Reformatted from actual json outline to compare against predicted outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c11e0f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: stories_with_outlines_first3000.jsonl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'story': 'Once upon a time, in a warm and sunny place, there was a big pit. A little boy named Tom liked to play near the pit. One day, Tom lost his red ball. He was very sad.\\nTom asked his friend, Sam, to help him search for the ball. They looked high and low, but they could not find the ball. Tom said, \"I think my ball fell into the pit.\"\\nSam and Tom went close to the pit. They were scared, but they wanted to find the red ball. They looked into the pit, but it was too dark to see. Tom said, \"We must go in and search for my ball.\"\\nThey went into the pit to search. It was dark and scary. They could not find the ball. They tried to get out, but the pit was too deep. Tom and Sam were stuck in the pit. They called for help, but no one could hear them. They were sad and scared, and they never got out of the pit.',\n",
       "  'outline': {'title': 'Tom and the Pit',\n",
       "   'characters': ['Tom', 'Sam'],\n",
       "   'setting': ['A warm and sunny place', 'A big pit'],\n",
       "   'events': {'e1_6a': {'rev': 1,\n",
       "     'summary': 'Tom enjoys playing near a big pit in a sunny location.',\n",
       "     'from_lines': [1, 2]},\n",
       "    'e0_f8': {'rev': 1,\n",
       "     'summary': 'Tom loses his red ball and feels very sad about it.',\n",
       "     'from_lines': [3, 4]},\n",
       "    'ea_60': {'rev': 1,\n",
       "     'summary': 'Tom asks his friend Sam for help, and they search for the ball without success.',\n",
       "     'from_lines': [5, 6]},\n",
       "    'e2_e2': {'rev': 1,\n",
       "     'summary': 'Tom suspects the ball fell into the pit, and he and Sam approach it despite their fear.',\n",
       "     'from_lines': [7, 8, 9]},\n",
       "    'e9_1a': {'rev': 1,\n",
       "     'summary': 'Determined to find the ball, Tom and Sam decide to go into the dark pit.',\n",
       "     'from_lines': [10, 11]},\n",
       "    'e8_3d': {'rev': 1,\n",
       "     'summary': 'Inside the pit, they search but cannot find the ball and realize they are stuck.',\n",
       "     'from_lines': [12, 13, 14]},\n",
       "    'e4_d0': {'rev': 1,\n",
       "     'summary': 'Tom and Sam call for help, but no one hears them, leaving them sad and scared.',\n",
       "     'from_lines': [15, 16]}},\n",
       "   'sequence': ['e1_6a', 'e0_f8', 'ea_60', 'e2_e2', 'e9_1a', 'e8_3d', 'e4_d0'],\n",
       "   'ending': {'summary': 'Tom and Sam remain trapped in the pit, feeling hopeless and frightened.'}}},\n",
       " {'story': 'Tom and Lily were playing with their toys in the living room. They liked to build towers and bridges with their blocks and cars. Tom was very proud of his tall tower. He wanted to make it even taller, so he reached for more blocks.\\n\"Tom, can I have some blocks too?\" Lily asked. She wanted to make a bridge for her cars.\\n\"No, these are mine. Go find your own,\" Tom said. He did not want to share with his sister. He pulled the blocks closer to him.\\nLily felt sad and angry. She did not think Tom was being nice. She looked at his tower and had an idea. She decided to pull one of the blocks at the bottom of the tower.\\nSuddenly, the tower fell down with a loud crash. All the blocks and cars scattered on the floor. Tom and Lily were shocked. They felt the floor shake and heard a rumble. It was an earthquake!\\n\"Mommy! Daddy!\" they cried. They were scared and ran to their parents, who were in the kitchen.\\n\"Are you okay, kids?\" Mommy asked. She hugged them and checked if they were hurt.\\n\"We\\'re okay, Mommy. But our toys are broken,\" Lily said.\\n\"I\\'m sorry, Lily. But toys are not important. You are important. We are safe and together. That\\'s what matters,\" Mommy said.\\nTom felt sorry for what he did. He realized he was selfish and mean to his sister. He saw how scared she was during the earthquake. He wanted to make her happy.\\n\"Lily, I\\'m sorry I did not share with you. You can have all the blocks you want. I love you, sister,\" Tom said.\\nLily smiled and hugged him. She forgave him and thanked him. She loved him too.\\nThey went back to the living room and cleaned up their toys. They decided to build something together. They made a big house with a garden and a fence. They put their cars and dolls inside. They were happy and proud of their work.\\nMommy and Daddy came to see their house. They praised them and gave them a treat. It was a lemon cake. It was sour, but they liked it. They learned that sharing is caring, and that family is sweet.',\n",
       "  'outline': {'title': \"Tom and Lily's Adventure\",\n",
       "   'characters': ['Tom', 'Lily', 'Mommy', 'Daddy'],\n",
       "   'setting': ['living room', 'kitchen'],\n",
       "   'events': {'e7_47': {'rev': 1,\n",
       "     'summary': 'Tom and Lily play with their toys, building towers and bridges.',\n",
       "     'from_lines': [1, 2]},\n",
       "    'e3_4f': {'rev': 1,\n",
       "     'summary': 'Tom is proud of his tall tower and refuses to share blocks with Lily.',\n",
       "     'from_lines': [3, 4, 5, 7, 9, 10]},\n",
       "    'ed_34': {'rev': 1,\n",
       "     'summary': \"Lily feels sad and angry, then decides to pull a block from Tom's tower.\",\n",
       "     'from_lines': [11, 13, 14]},\n",
       "    'e0_04': {'rev': 1,\n",
       "     'summary': 'The tower falls down during an earthquake, shocking both children.',\n",
       "     'from_lines': [15, 16, 17, 19]},\n",
       "    'ec_56': {'rev': 1,\n",
       "     'summary': 'Tom and Lily run to their parents for comfort after the earthquake.',\n",
       "     'from_lines': [20, 22, 23]},\n",
       "    'e9_56': {'rev': 1,\n",
       "     'summary': 'Mommy reassures them that they are safe and emphasizes the importance of family.',\n",
       "     'from_lines': [25, 31]},\n",
       "    'ee_27': {'rev': 1,\n",
       "     'summary': 'Tom apologizes to Lily for not sharing and expresses his love for her.',\n",
       "     'from_lines': [32, 36, 38]},\n",
       "    'e0_35': {'rev': 1,\n",
       "     'summary': 'Lily forgives Tom, and they decide to build something together.',\n",
       "     'from_lines': [39, 40, 43]},\n",
       "    'ef_ba': {'rev': 1,\n",
       "     'summary': 'They create a big house with a garden and are proud of their work.',\n",
       "     'from_lines': [44, 46]},\n",
       "    'ef_72': {'rev': 1,\n",
       "     'summary': 'Mommy and Daddy praise their creation and reward them with a treat.',\n",
       "     'from_lines': [47, 49]},\n",
       "    'ec_89': {'rev': 1,\n",
       "     'summary': 'Tom and Lily learn the value of sharing and the sweetness of family.',\n",
       "     'from_lines': [51]}},\n",
       "   'sequence': ['e7_47',\n",
       "    'e3_4f',\n",
       "    'ed_34',\n",
       "    'e0_04',\n",
       "    'ec_56',\n",
       "    'e9_56',\n",
       "    'ee_27',\n",
       "    'e0_35',\n",
       "    'ef_ba',\n",
       "    'ef_72',\n",
       "    'ec_89'],\n",
       "   'ending': {'summary': 'Tom and Lily realize the importance of sharing and family after their adventure.'}}},\n",
       " {'story': 'Once upon a time there was a little girl named Lucy. She loved to go to the store to buy sweets with her mom and dad. On this special day, Lucy entered the store with her mom and dad, feeling so excited.\\nAs they were looking around, Lucy noticed a little girl playing with a toy in the corner of the store. She gasped in excitement and ran towards her. Lucy asked if she could play too but the little girl said no. She was rather grumpy and was not in the mood to play.\\nLucy\\'s mom saw what was going on and told Lucy, \"Let\\'s try to be peaceful and kind to her. Have patience and understanding. Together, you can both be happy!\"\\nSo, Lucy smiled at the girl and said, \"Can we play together?\" The little girl softened and smiled back. She agreed to share the toy and even let Lucy have a turn first.\\nLucy and the little girl played together happily. In the end, they both learnt an important lesson: be peaceful, kind, and understanding when faced with a conflict. And that is why Lucy and the little girl became great friends.',\n",
       "  'outline': {'title': 'Lucy and the Little Girl',\n",
       "   'characters': ['Lucy', \"Lucy's mom\", \"Lucy's dad\", 'the little girl'],\n",
       "   'setting': ['a store'],\n",
       "   'events': {'e3_71': {'rev': 1,\n",
       "     'summary': 'Lucy, a little girl, loves visiting the store with her parents to buy sweets.',\n",
       "     'from_lines': [1, 2]},\n",
       "    'e6_ef': {'rev': 1,\n",
       "     'summary': 'On a special day, Lucy enters the store with excitement and notices another girl playing with a toy.',\n",
       "     'from_lines': [3, 4]},\n",
       "    'e8_cc': {'rev': 1,\n",
       "     'summary': 'Lucy approaches the girl to play, but the girl refuses and appears grumpy.',\n",
       "     'from_lines': [5, 6, 7]},\n",
       "    'e0_a3': {'rev': 1,\n",
       "     'summary': \"Lucy's mom encourages her to be kind and patient with the other girl.\",\n",
       "     'from_lines': [8, 9, 10]},\n",
       "    'e4_46': {'rev': 1,\n",
       "     'summary': 'Lucy smiles and asks to play together, which softens the other girl, leading to a shared playtime.',\n",
       "     'from_lines': [10, 11, 12]},\n",
       "    'ee_cf': {'rev': 1,\n",
       "     'summary': 'Both girls learn the importance of kindness and understanding, resulting in a new friendship.',\n",
       "     'from_lines': [13, 14]}},\n",
       "   'sequence': ['e3_71', 'e6_ef', 'e8_cc', 'e0_a3', 'e4_46', 'ee_cf'],\n",
       "   'ending': {'summary': 'Lucy and the little girl become great friends after learning to be peaceful and kind.'}}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Loading dataset: {DATA_FILE}\")\n",
    "# Read all lines as JSON\n",
    "mockdata = []\n",
    "with open(DATA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        each_line = json.loads(line)\n",
    "        # extract story text\n",
    "        story = each_line['story']\n",
    "        # extract json outline\n",
    "        outline = each_line['outline']\n",
    "        # append to dataset\n",
    "        mockdata.append({\"story\": story, \"outline\": outline})\n",
    "        \n",
    "mockdata[:3] # preview first 3 entries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21787d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: stories_with_outlines_first3000.jsonl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'story': 'Once upon a time, in a warm and sunny place, there was a big pit. A little boy named Tom liked to play near the pit. One day, Tom lost his red ball. He was very sad.\\nTom asked his friend, Sam, to help him search for the ball. They looked high and low, but they could not find the ball. Tom said, \"I think my ball fell into the pit.\"\\nSam and Tom went close to the pit. They were scared, but they wanted to find the red ball. They looked into the pit, but it was too dark to see. Tom said, \"We must go in and search for my ball.\"\\nThey went into the pit to search. It was dark and scary. They could not find the ball. They tried to get out, but the pit was too deep. Tom and Sam were stuck in the pit. They called for help, but no one could hear them. They were sad and scared, and they never got out of the pit.',\n",
       "  'events': 'Tom enjoys playing near a big pit in a sunny location. Tom loses his red ball and feels very sad about it. Tom asks his friend Sam for help, and they search for the ball without success. Tom suspects the ball fell into the pit, and he and Sam approach it despite their fear. Determined to find the ball, Tom and Sam decide to go into the dark pit. Inside the pit, they search but cannot find the ball and realize they are stuck. Tom and Sam call for help, but no one hears them, leaving them sad and scared. ',\n",
       "  'title': 'Tom and the Pit',\n",
       "  'settings': ['A warm and sunny place', 'A big pit'],\n",
       "  'characters': ['Tom', 'Sam'],\n",
       "  'ending': 'Tom and Sam remain trapped in the pit, feeling hopeless and frightened.'},\n",
       " {'story': 'Tom and Lily were playing with their toys in the living room. They liked to build towers and bridges with their blocks and cars. Tom was very proud of his tall tower. He wanted to make it even taller, so he reached for more blocks.\\n\"Tom, can I have some blocks too?\" Lily asked. She wanted to make a bridge for her cars.\\n\"No, these are mine. Go find your own,\" Tom said. He did not want to share with his sister. He pulled the blocks closer to him.\\nLily felt sad and angry. She did not think Tom was being nice. She looked at his tower and had an idea. She decided to pull one of the blocks at the bottom of the tower.\\nSuddenly, the tower fell down with a loud crash. All the blocks and cars scattered on the floor. Tom and Lily were shocked. They felt the floor shake and heard a rumble. It was an earthquake!\\n\"Mommy! Daddy!\" they cried. They were scared and ran to their parents, who were in the kitchen.\\n\"Are you okay, kids?\" Mommy asked. She hugged them and checked if they were hurt.\\n\"We\\'re okay, Mommy. But our toys are broken,\" Lily said.\\n\"I\\'m sorry, Lily. But toys are not important. You are important. We are safe and together. That\\'s what matters,\" Mommy said.\\nTom felt sorry for what he did. He realized he was selfish and mean to his sister. He saw how scared she was during the earthquake. He wanted to make her happy.\\n\"Lily, I\\'m sorry I did not share with you. You can have all the blocks you want. I love you, sister,\" Tom said.\\nLily smiled and hugged him. She forgave him and thanked him. She loved him too.\\nThey went back to the living room and cleaned up their toys. They decided to build something together. They made a big house with a garden and a fence. They put their cars and dolls inside. They were happy and proud of their work.\\nMommy and Daddy came to see their house. They praised them and gave them a treat. It was a lemon cake. It was sour, but they liked it. They learned that sharing is caring, and that family is sweet.',\n",
       "  'events': \"Tom and Lily play with their toys, building towers and bridges. Tom is proud of his tall tower and refuses to share blocks with Lily. Lily feels sad and angry, then decides to pull a block from Tom's tower. The tower falls down during an earthquake, shocking both children. Tom and Lily run to their parents for comfort after the earthquake. Mommy reassures them that they are safe and emphasizes the importance of family. Tom apologizes to Lily for not sharing and expresses his love for her. Lily forgives Tom, and they decide to build something together. They create a big house with a garden and are proud of their work. Mommy and Daddy praise their creation and reward them with a treat. Tom and Lily learn the value of sharing and the sweetness of family. \",\n",
       "  'title': \"Tom and Lily's Adventure\",\n",
       "  'settings': ['living room', 'kitchen'],\n",
       "  'characters': ['Tom', 'Lily', 'Mommy', 'Daddy'],\n",
       "  'ending': 'Tom and Lily realize the importance of sharing and family after their adventure.'},\n",
       " {'story': 'Once upon a time there was a little girl named Lucy. She loved to go to the store to buy sweets with her mom and dad. On this special day, Lucy entered the store with her mom and dad, feeling so excited.\\nAs they were looking around, Lucy noticed a little girl playing with a toy in the corner of the store. She gasped in excitement and ran towards her. Lucy asked if she could play too but the little girl said no. She was rather grumpy and was not in the mood to play.\\nLucy\\'s mom saw what was going on and told Lucy, \"Let\\'s try to be peaceful and kind to her. Have patience and understanding. Together, you can both be happy!\"\\nSo, Lucy smiled at the girl and said, \"Can we play together?\" The little girl softened and smiled back. She agreed to share the toy and even let Lucy have a turn first.\\nLucy and the little girl played together happily. In the end, they both learnt an important lesson: be peaceful, kind, and understanding when faced with a conflict. And that is why Lucy and the little girl became great friends.',\n",
       "  'events': \"Lucy, a little girl, loves visiting the store with her parents to buy sweets. On a special day, Lucy enters the store with excitement and notices another girl playing with a toy. Lucy approaches the girl to play, but the girl refuses and appears grumpy. Lucy's mom encourages her to be kind and patient with the other girl. Lucy smiles and asks to play together, which softens the other girl, leading to a shared playtime. Both girls learn the importance of kindness and understanding, resulting in a new friendship. \",\n",
       "  'title': 'Lucy and the Little Girl',\n",
       "  'settings': ['a store'],\n",
       "  'characters': ['Lucy', \"Lucy's mom\", \"Lucy's dad\", 'the little girl'],\n",
       "  'ending': 'Lucy and the little girl become great friends after learning to be peaceful and kind.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Loading dataset: {DATA_FILE}\")\n",
    "# Read all lines as JSON\n",
    "dataset = []\n",
    "with open(DATA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        each_line = json.loads(line)\n",
    "        # extract story text\n",
    "        story = each_line['story']\n",
    "        # extract and reformat outline details: events + title\n",
    "        outline = each_line['outline']\n",
    "        title = outline.get('title', '')\n",
    "        events = outline.get('events', [])\n",
    "        full_summary = \"\"\n",
    "        for key, value in events.items():\n",
    "            summary = value.get('summary')\n",
    "            full_summary += f\"{summary} \"\n",
    "        # extract ending & settings & characters\n",
    "        ending = outline['ending'].get('summary')\n",
    "        char = outline.get('characters')\n",
    "        setting = outline.get('setting')\n",
    "\n",
    "        # append to dataset\n",
    "        dataset.append({\"story\": story, \"events\": full_summary,\n",
    "                         \"title\": title, \"settings\": setting, \"characters\": char, \"ending\": ending})\n",
    "\n",
    "\n",
    "dataset[:3] # preview first 3 entries "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4140d0a",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e33ee964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count sentences\n",
    "def count_sentences(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    return len(sentences)\n",
    "\n",
    "# helper: average word vectors for a sentence\n",
    "def sentence_vector(sentence, model):\n",
    "    words = [w for w in word_tokenize(sentence.lower()) if w in model.wv]\n",
    "    if not words:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(model.wv[words], axis=0)\n",
    "\n",
    "# helper: cosine similarity\n",
    "def cosine_sim(vec1, vec2):\n",
    "    if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:\n",
    "        return 0\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# main function: semantic chunking\n",
    "def split_story_by_similarity(story: str, model: Word2Vec, threshold: float = 0.7) -> list:\n",
    "    sentences = sent_tokenize(story)\n",
    "    if len(sentences) <= 1:\n",
    "        return [story]\n",
    "    chunks = []\n",
    "    from_lines = []\n",
    "    current_chunk = [sentences[0]]\n",
    "    current_lines = [1]  # Start tracking line numbers from 1\n",
    "    prev_vec = sentence_vector(sentences[0], model)\n",
    "    for i in range(1, len(sentences)):\n",
    "        curr_vec = sentence_vector(sentences[i], model)\n",
    "        sim = cosine_sim(prev_vec, curr_vec)\n",
    "        if sim < threshold:\n",
    "            # new context detected â†’ start new chunk\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            # record line numbers (1-based) of sentences in this chunk\n",
    "            from_lines.append(\", \".join(str(x) for x in current_lines))\n",
    "            current_chunk = [sentences[i]]\n",
    "            current_lines = [i + 1]  # Reset with current line number\n",
    "        else:\n",
    "            current_chunk.append(sentences[i])\n",
    "            current_lines.append(i + 1)  # Add line number to current chunk\n",
    "        prev_vec = curr_vec\n",
    "    # add the last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "        from_lines.append(\", \".join(str(x) for x in current_lines))\n",
    "    return chunks, from_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a23cef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper: generate short event ID\n",
    "def short_event_id(summary: str) -> str:\n",
    "    \"\"\"Deterministic short ID from summary text.\"\"\"\n",
    "    h = hashlib.sha1(summary.encode(\"utf-8\")).hexdigest()\n",
    "    return f\"e{h[:1]}_{h[1:3]}\"\n",
    "\n",
    "# helper: convert str into list of str\n",
    "def text_to_list(text: str):\n",
    "    # Split by commas\n",
    "    items = [item.strip() for item in text.split(',')]\n",
    "    # Remove extra whitespace & capitalize properly\n",
    "    items = [re.sub(r'\\s+', ' ', item).strip().title() for item in items if item.strip()]\n",
    "    return list(set(items)) # to remove duplicate elements\n",
    "\n",
    "# helper: generate event summary\n",
    "def summarise_this_event(event_model, event_tokenizer, chunk: str, device) -> str:\n",
    "    prompt = f\"Summarise this text:\\n{chunk}\\n\"\n",
    "    inputs = event_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = event_tokenizer.decode(\n",
    "        event_model.generate(**inputs, max_new_tokens=128)[0], skip_special_tokens=True \n",
    "    )\n",
    "    return outputs\n",
    "\n",
    "# helper: generate story title\n",
    "def generate_title(qa_model, qa_tokenizer, story: str, device) -> str:\n",
    "    title_prompt = f\"Question: What is a good title for this story? \\nStory: {story}\"\n",
    "    title_input = qa_tokenizer(title_prompt, return_tensors=\"pt\").to(device)\n",
    "    title_output = qa_tokenizer.decode(\n",
    "        qa_model.generate(**title_input, max_new_tokens=64)[0], skip_special_tokens=True       \n",
    "    )\n",
    "    return title_output\n",
    "\n",
    "# helper: generate story characters\n",
    "def generate_char(qa_model, qa_tokenizer, story: str, device) -> list[str]:\n",
    "    char_prompt = f\"Question: Who are the characters in this story? \\nStory: {story}\"\n",
    "    char_input = qa_tokenizer(char_prompt, return_tensors=\"pt\").to(device)\n",
    "    char_output = qa_tokenizer.decode(\n",
    "        qa_model.generate(**char_input, max_new_tokens=64)[0], skip_special_tokens=True       \n",
    "    )\n",
    "    char_output = text_to_list(char_output)\n",
    "    return char_output\n",
    "\n",
    "# helper: generate story settings\n",
    "def generate_setting(qa_model, qa_tokenizer, story: str, device) -> list[str]:\n",
    "    settings_prompt = f\"Question: What are all the settings in this story? \\nStory: {story}\"\n",
    "    settings_input = qa_tokenizer(settings_prompt, return_tensors=\"pt\").to(device)\n",
    "    settings_output = qa_tokenizer.decode(\n",
    "        qa_model.generate(**settings_input, max_new_tokens=64)[0], skip_special_tokens=True       \n",
    "    )\n",
    "    settings_output = text_to_list(settings_output)\n",
    "    return settings_output\n",
    "\n",
    "# helper: generate story ending\n",
    "def generate_ending(ending_model, ending_tokenizer, story: str, device) -> str:\n",
    "    ending_prompt = f\"Extract the ending for this text: \\n{story}\"\n",
    "    ending_input = ending_tokenizer(ending_prompt, return_tensors=\"pt\").to(device)\n",
    "    ending_output = ending_tokenizer.decode(\n",
    "        ending_model.generate(**ending_input, max_new_tokens=128)[0], skip_special_tokens=True       \n",
    "    )\n",
    "    return ending_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e124b2b",
   "metadata": {},
   "source": [
    "# Testing Actual JSON outliner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30a6d142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Original Story Title: Blink and Blue\n",
      "Generated Model title: A Beautiful oasis\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Original Characters: ['Blink', 'Blue']\n",
      "Generated Characters: ['Blink', 'Blue']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Original Settings: ['a large, hot desert', 'an oasis']\n",
      "Generated Settings: ['Oasis', 'Hot Desert']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Original Ending: Blink and Blue's friendship blossomed as they enjoyed their time together in the oasis.\n",
      "Generated Ending: Blue and Blink have been friends since the beginning of their friendship.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test run everything except events(in the next cell)\n",
    "INDEX = random.randint(0, 2999)\n",
    "story = dataset[INDEX][\"story\"]\n",
    "event = dataset[INDEX][\"events\"]\n",
    "title = dataset[INDEX][\"title\"]\n",
    "characters = dataset[INDEX][\"characters\"]\n",
    "settings = dataset[INDEX][\"settings\"]\n",
    "ending = dataset[INDEX][\"ending\"]\n",
    "dashline = \"-\" * 80\n",
    "print(dashline)\n",
    "\n",
    "# Compare original and predicted title\n",
    "print(f\"Original Story Title: {title}\")\n",
    "pred_title = generate_title(qa_model, qa_tokenizer, story, DEVICE)\n",
    "print(f\"Generated Model title: {pred_title}\\n\")\n",
    "print(dashline)\n",
    "\n",
    "# Compare original and predicted characters\n",
    "print(f\"Original Characters: {characters}\")\n",
    "pred_char = generate_char(qa_model, qa_tokenizer, story, DEVICE)\n",
    "print(f\"Generated Characters: {pred_char}\\n\")\n",
    "print(dashline)\n",
    "\n",
    "# Compare original and predicted settings\n",
    "print(f\"Original Settings: {settings}\")\n",
    "pred_settings = generate_setting(qa_model, qa_tokenizer, story, DEVICE)\n",
    "print(f\"Generated Settings: {pred_settings}\\n\")\n",
    "print(dashline)\n",
    "\n",
    "# Compare original and predicted ending\n",
    "print(f\"Original Ending: {ending}\")\n",
    "pred_ending = generate_ending(ending_model, ending_tokenizer, story, DEVICE)\n",
    "print(f\"Generated Ending: {pred_ending}\\n\")\n",
    "print(dashline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec173bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outlined events based on actual JSON summary: 6\n",
      "\n",
      "--- Chunk 1 ---\n",
      "From line(s): 1, 2, 3, 4, 5, 6, 7\n",
      "Once upon a time, in a large, hot desert, there was a beautiful oasis. In the oasis, lived a tiny bug named Blink. Blink was a happy bug who liked to play with his friends. The oasis was full of water, trees, and fun. One day, while Blink was playing, he met a big bird named Blue. Blue was very thirsty and asked Blink, \"Where can I find water to drink?\" Blink knew where the water was and wanted to help.\n",
      "chunk summary: In a large desert, Blink is a happy bug who loves playing with his friends.\n",
      "--- Chunk 2 ---\n",
      "From line(s): 8, 9, 10, 11, 12, 13\n",
      "He said, \"Follow me, Blue, I will show you the water.\" So, Blue followed Blink to the water in the oasis. Blue was very happy to see the water and drank a lot. Blue thanked Blink and said, \"You are a good friend, Blink.\" From that day on, Blink and Blue became best friends. They played together at the oasis every day, and everyone knew that the tiny bug and the big bird were the best of friends.\n",
      "chunk summary: Blue and Blink enjoy the water in the oasis, and they become best friends.\n"
     ]
    }
   ],
   "source": [
    "# Test run event summary\n",
    "print(f\"Number of outlined events based on actual JSON summary: {count_sentences(event)}\\n\")\n",
    "sentences = [word_tokenize(s.lower()) for s in sent_tokenize(story)]\n",
    "w2v_model = Word2Vec(sentences, vector_size=150, window=5, min_count=1, workers=2)\n",
    "\n",
    "\n",
    "# MAYBE THIS COULD BE PART OF ABLATION STUDY\n",
    "# THRESHOLD TUNING: if too many chunks, lower threshold; if too few, increase\n",
    "THRESHOLD = 0.2\n",
    "\n",
    "# split story into semantically coherent chunks\n",
    "chunks, from_lines = split_story_by_similarity(story, w2v_model, threshold=THRESHOLD)\n",
    "\n",
    "for i, c in enumerate(chunks, 1):\n",
    "    print(f\"--- Chunk {i} ---\")\n",
    "    print(f\"From line(s): {from_lines[i-1]}\")\n",
    "    print(c)\n",
    "    chunk_summary = summarise_this_event(event_model, event_tokenizer, c, DEVICE)\n",
    "    print(f\"chunk summary: {chunk_summary}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b6c80a",
   "metadata": {},
   "source": [
    "# JSON output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d117a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns a structured json schema\n",
    "def generate_json_outline(story,\n",
    "                          qa_model=qa_model, qa_tokenizer=qa_tokenizer,\n",
    "                          ending_model=ending_model, ending_tokenizer=ending_tokenizer,\n",
    "                          event_model=event_model, event_tokenizer=event_tokenizer,\n",
    "                          chunk_similarity_threshold=0.2, device=DEVICE):\n",
    "    # JSON schema to be returned\n",
    "    summary_json = {\n",
    "        \"title\": None,\n",
    "        \"characters\": None,\n",
    "        \"settings\": None,\n",
    "        \"events\": {},\n",
    "        \"sequence\": [],\n",
    "        \"ending\": None\n",
    "    }\n",
    "    # split story into semantically coherent chunks first\n",
    "    sentences = [word_tokenize(s.lower()) for s in sent_tokenize(story)]\n",
    "    w2v_model = Word2Vec(sentences, vector_size=150, window=5, min_count=1, workers=2)\n",
    "    event_chunks, from_lines = split_story_by_similarity(story, w2v_model, chunk_similarity_threshold)\n",
    "    # populate events and sequence\n",
    "    for i in range(len(event_chunks)):\n",
    "        # generate json entry for each event summary\n",
    "        curr_chunk_summary = summarise_this_event(event_model, event_tokenizer, event_chunks[i], device)\n",
    "        event_id = short_event_id(curr_chunk_summary)\n",
    "        summary_json[\"events\"][event_id] = {\n",
    "            \"rev\": 1, # revision number will always be 1 for generated outlines\n",
    "            \"summary\": curr_chunk_summary,\n",
    "            # convert from_lines to list of integers\n",
    "            \"from_lines\": list(map(int, from_lines[i].split(\", \")))\n",
    "        }\n",
    "        # add event id to sequence\n",
    "        summary_json[\"sequence\"].append(event_id)\n",
    "    # populate title, characters, settings & ending\n",
    "    title = generate_title(qa_model, qa_tokenizer, story, device)\n",
    "    char = generate_char(qa_model, qa_tokenizer, story, device) \n",
    "    setting = generate_setting(qa_model, qa_tokenizer, story, device)\n",
    "    ending = generate_ending(ending_model, ending_tokenizer, story, device)\n",
    "    summary_json[\"title\"] = title\n",
    "    summary_json[\"characters\"] = char\n",
    "    summary_json[\"settings\"] = setting\n",
    "    summary_json[\"ending\"] = ending\n",
    "\n",
    "    return summary_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67f42555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"title\": \"Tim and Sue's Peach\",\n",
      "   \"characters\": [\n",
      "      \"Sue\",\n",
      "      \"Tim\"\n",
      "   ],\n",
      "   \"settings\": [\n",
      "      \"The Store\"\n",
      "   ],\n",
      "   \"events\": {\n",
      "      \"ed_37\": {\n",
      "         \"rev\": 1,\n",
      "         \"summary\": \"Tim is tired and goes to the store to buy a peach, and his friend Sue tells him to stay away.\",\n",
      "         \"from_lines\": [\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "            4\n",
      "         ]\n",
      "      },\n",
      "      \"e5_bd\": {\n",
      "         \"rev\": 1,\n",
      "         \"summary\": \"Tim and Sue walked to her bike, and they noticed the bike was broken.\",\n",
      "         \"from_lines\": [\n",
      "            5,\n",
      "            6,\n",
      "            7,\n",
      "            8,\n",
      "            9\n",
      "         ]\n",
      "      },\n",
      "      \"e6_4c\": {\n",
      "         \"rev\": 1,\n",
      "         \"summary\": \"Sue is happy and unexpectedly happens.\",\n",
      "         \"from_lines\": [\n",
      "            10,\n",
      "            11\n",
      "         ]\n",
      "      },\n",
      "      \"e7_ea\": {\n",
      "         \"rev\": 1,\n",
      "         \"summary\": \"Tim picks up the peach and begins to talk, expressing his gratitude to Sue.\",\n",
      "         \"from_lines\": [\n",
      "            12,\n",
      "            13\n",
      "         ]\n",
      "      },\n",
      "      \"ee_59\": {\n",
      "         \"rev\": 1,\n",
      "         \"summary\": \"The peach is a magic peach.\",\n",
      "         \"from_lines\": [\n",
      "            14\n",
      "         ]\n",
      "      },\n",
      "      \"ec_79\": {\n",
      "         \"rev\": 1,\n",
      "         \"summary\": \"Then, I give you energy so you are not tired anymore.\",\n",
      "         \"from_lines\": [\n",
      "            15\n",
      "         ]\n",
      "      },\n",
      "      \"e3_ae\": {\n",
      "         \"rev\": 1,\n",
      "         \"summary\": \"Tim ate the peach and felt better, both laughed and played all day.\",\n",
      "         \"from_lines\": [\n",
      "            16,\n",
      "            17\n",
      "         ]\n",
      "      }\n",
      "   },\n",
      "   \"sequence\": [\n",
      "      \"ed_37\",\n",
      "      \"e5_bd\",\n",
      "      \"e6_4c\",\n",
      "      \"e7_ea\",\n",
      "      \"ee_59\",\n",
      "      \"ec_79\",\n",
      "      \"e3_ae\"\n",
      "   ],\n",
      "   \"ending\": \"Tim and Sue enjoy the peach and feel better.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test JSON output generation\n",
    "INDEX = random.randint(0, 2999)\n",
    "story = dataset[INDEX][\"story\"]\n",
    "THRESHOLD = 0.15 # edit this to obtain diff variation of event outlines\n",
    "json_outline = generate_json_outline(story, chunk_similarity_threshold=THRESHOLD)\n",
    "print(json.dumps(json_outline, indent=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
