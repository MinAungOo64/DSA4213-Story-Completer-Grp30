{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e2cf62",
   "metadata": {},
   "source": [
    "# Finetuning model for Title/Characters/Settings extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46e62adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Keven(Work)\\dsa4213\\final project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to d:\\Keven(Work)\\dsa4213\\final\n",
      "[nltk_data]     project\\venv\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     d:\\Keven(Work)\\dsa4213\\final project\\venv\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     d:\\Keven(Work)\\dsa4213\\final project\\venv\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n",
    "import evaluate\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Make sure the required NLTK data packages are available\n",
    "# Dynamically construct NLTK data directory relative to current working directory\n",
    "nltk_data_dir = os.path.join(os.getcwd(), \"venv\", \"nltk_data\")\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(nltk_data_dir, exist_ok=True)\n",
    "\n",
    "nltk.download(\"punkt\", download_dir=nltk_data_dir)\n",
    "nltk.download('punkt_tab', download_dir=nltk_data_dir)\n",
    "nltk.download(\"stopwords\", download_dir=nltk_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "806e5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "def set_seed(seed=4213):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(4213)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4470fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "# ==============================\n",
    "TRAIN_FILE = \"stories_with_outlines_first3000.jsonl\"\n",
    "OUTPUT_DIR = \"./QA-LoRA-v2\"\n",
    "BASE_MODEL = \"t5-small\"\n",
    "USE_LORA = True\n",
    "MAX_INPUT_LENGTH = 768\n",
    "MAX_TARGET_LENGTH = 64\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8685930",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21787d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading each event dataset: stories_with_outlines_first3000.jsonl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Question: Who are the characters in this story? \\nStory: Once upon a time, in a warm and sunny place, there was a big pit. A little boy named Tom liked to play near the pit. One day, Tom lost his red ball. He was very sad.\\nTom asked his friend, Sam, to help him search for the ball. They looked high and low, but they could not find the ball. Tom said, \"I think my ball fell into the pit.\"\\nSam and Tom went close to the pit. They were scared, but they wanted to find the red ball. They looked into the pit, but it was too dark to see. Tom said, \"We must go in and search for my ball.\"\\nThey went into the pit to search. It was dark and scary. They could not find the ball. They tried to get out, but the pit was too deep. Tom and Sam were stuck in the pit. They called for help, but no one could hear them. They were sad and scared, and they never got out of the pit.',\n",
       "  'response': 'Tom, Sam'},\n",
       " {'instruction': 'Question: What are all the settings in this story? \\nStory: Once upon a time, in a warm and sunny place, there was a big pit. A little boy named Tom liked to play near the pit. One day, Tom lost his red ball. He was very sad.\\nTom asked his friend, Sam, to help him search for the ball. They looked high and low, but they could not find the ball. Tom said, \"I think my ball fell into the pit.\"\\nSam and Tom went close to the pit. They were scared, but they wanted to find the red ball. They looked into the pit, but it was too dark to see. Tom said, \"We must go in and search for my ball.\"\\nThey went into the pit to search. It was dark and scary. They could not find the ball. They tried to get out, but the pit was too deep. Tom and Sam were stuck in the pit. They called for help, but no one could hear them. They were sad and scared, and they never got out of the pit.',\n",
       "  'response': 'A warm and sunny place, A big pit'},\n",
       " {'instruction': 'Question: What is a good title for this story? \\nStory: Once upon a time, in a warm and sunny place, there was a big pit. A little boy named Tom liked to play near the pit. One day, Tom lost his red ball. He was very sad.\\nTom asked his friend, Sam, to help him search for the ball. They looked high and low, but they could not find the ball. Tom said, \"I think my ball fell into the pit.\"\\nSam and Tom went close to the pit. They were scared, but they wanted to find the red ball. They looked into the pit, but it was too dark to see. Tom said, \"We must go in and search for my ball.\"\\nThey went into the pit to search. It was dark and scary. They could not find the ball. They tried to get out, but the pit was too deep. Tom and Sam were stuck in the pit. They called for help, but no one could hear them. They were sad and scared, and they never got out of the pit.',\n",
       "  'response': 'Tom and the Pit'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in raw data\n",
    "\n",
    "print(f\"Loading each event dataset: {TRAIN_FILE}\")\n",
    "# Read all lines as JSON\n",
    "raw_data = []\n",
    "with open(TRAIN_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        each_line = json.loads(line)\n",
    "        # extract story text and reformat input\n",
    "        story = each_line['story']\n",
    "        question1 = \"Question: Who are the characters in this story?\"\n",
    "        char_input = f\"{question1} \\nStory: {story}\"\n",
    "        question2 = \"Question: What are all the settings in this story?\"\n",
    "        setting_input = f\"{question2} \\nStory: {story}\"\n",
    "        question3 = \"Question: What is a good title for this story?\"\n",
    "        title_input = f\"{question3} \\nStory: {story}\"\n",
    "        # extract outline details: characters + settings\n",
    "        outline = each_line['outline']\n",
    "        char = \", \".join(outline.get(\"characters\"))\n",
    "        setting = \", \".join(outline.get(\"setting\"))\n",
    "        title = outline.get(\"title\")\n",
    "        # append to dataset\n",
    "        raw_data.append({\"instruction\": char_input, \"response\": char})\n",
    "        raw_data.append({\"instruction\": setting_input, \"response\": setting})\n",
    "        raw_data.append({\"instruction\": title_input, \"response\": title})\n",
    "\n",
    "raw_data[:3]  # preview first 3 entries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "351e09a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model: t5-small\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'response'],\n",
       "        num_rows: 8910\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'response'],\n",
       "        num_rows: 90\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_list(raw_data)\n",
    "dataset = dataset.train_test_split(test_size=0.01)\n",
    "\n",
    "# Prepare tokenizer and model\n",
    "print(f\"Loading base model: {BASE_MODEL}\")\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(BASE_MODEL).to(DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92779212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing dataset:   0%|          | 0/8910 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing dataset: 100%|██████████| 8910/8910 [00:05<00:00, 1511.83 examples/s]\n",
      "Tokenizing dataset: 100%|██████████| 90/90 [00:00<00:00, 1363.62 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_function(batch):\n",
    "    model_inputs = tokenizer(\n",
    "        batch[\"instruction\"],\n",
    "        max_length=MAX_INPUT_LENGTH,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        text_target=batch[\"response\"],\n",
    "        max_length=MAX_TARGET_LENGTH,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        )  \n",
    "    # Replace pad token IDs with -100 so they’re ignored in cross-entropy loss\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(token if token != tokenizer.pad_token_id else -100) for token in label]\n",
    "        for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_dataset = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"instruction\", \"response\"],\n",
    "    desc=\"Tokenizing dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d45665c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Story:\n",
      "Question: Who are the characters in this story? \n",
      "Story: Once upon a time, in a big forest, there lived a little girl named Lily. She loved to play with her toys and equipment. One day, she found a rare, shiny stone while playing outside.\n",
      "Lily showed the stone to her friend, Tom. \"Guess what I found!\" she said. \"Wow, that's a rare stone!\" Tom replied. They were both very happy and excited.\n",
      "Together, they decided to make a special place for the rare stone. They used their equipment to dig a small hole and put the stone inside. They covered it with leaves and branches. Lily and Tom promised to always remember where their rare stone was hidden. And they played and laughed together, having lots of fun in the big forest.\n",
      "--------------------------------------------------------------------------------\n",
      "Expected output:\n",
      "Lily, Tom\n",
      "--------------------------------------------------------------------------------\n",
      "Model Output:\n",
      "Lily and Tom were both very happy and excited. Lily and Tom promised to always remember where their rare stone was hidden.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test current model with zero shot inference\n",
    "from torch import no_grad\n",
    "\n",
    "# use one example from test set\n",
    "story = dataset['test'][67][\"instruction\"]\n",
    "answer = dataset['test'][67][\"response\"]\n",
    "\n",
    "# Tokenise input\n",
    "inputs = tokenizer(story, return_tensors=\"pt\", max_length=MAX_INPUT_LENGTH, truncation=True).to(DEVICE)\n",
    "# Generate output and decode\n",
    "with no_grad():\n",
    "    outputs = base_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=MAX_TARGET_LENGTH,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "base_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "dashline = \"-\" * 80\n",
    "print(dashline)\n",
    "print(\"Story:\")\n",
    "print(story)\n",
    "print(dashline)\n",
    "print(\"Expected output:\")  \n",
    "print(answer)\n",
    "print(dashline)\n",
    "print(\"Model Output:\")\n",
    "print(base_output)\n",
    "print(dashline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea12afe",
   "metadata": {},
   "source": [
    "# PEFT model using LoRA\n",
    "(skip the cells in this section if not finetuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70222c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA adapter for lightweight fine-tuning...\n",
      "trainable params: 1,179,648 || all params: 61,686,272 || trainable%: 1.9123\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# LoRA configuration\n",
    "if USE_LORA:\n",
    "    print(\"Applying LoRA adapter for lightweight fine-tuning...\")\n",
    "    lora_config = LoraConfig(\n",
    "        r=32,\n",
    "        lora_alpha=128,\n",
    "        target_modules=[\"q\", \"v\"],\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"SEQ_2_SEQ_LM\",\n",
    "    )\n",
    "lora_model = get_peft_model(base_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "lora_model = lora_model.to(DEVICE)\n",
    "\n",
    "# PEFT Training configuration\n",
    "peft_training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    auto_find_batch_size=True,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=3e-5,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    predict_with_generate=True,\n",
    "    report_to=\"none\",  # disable wandb/tensorboard\n",
    "    save_strategy=\"steps\",  \n",
    "    save_steps=50,          \n",
    "    save_total_limit=3,     \n",
    "    logging_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=lora_model\n",
    ")\n",
    "\n",
    "# PEFT Trainer setup\n",
    "peft_trainer = Trainer(  \n",
    "    model=lora_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "591d361d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "No existing checkpoint found — starting fresh training.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='837' max='837' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [837/837 12:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>2.723700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>558</td>\n",
       "      <td>1.809600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>837</td>\n",
       "      <td>1.678600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving LoRA fine-tuned model to ./QA-LoRA-v2\n"
     ]
    }
   ],
   "source": [
    "# Initiate training\n",
    "\n",
    "print(\"Starting training...\")\n",
    "# Resume only if checkpoint exists\n",
    "resume_checkpoint = None\n",
    "last_checkpoint_dir = os.path.join(OUTPUT_DIR, \"checkpoint-last\")\n",
    "if os.path.isdir(last_checkpoint_dir):\n",
    "    resume_checkpoint = last_checkpoint_dir\n",
    "    print(f\"Resuming from checkpoint: {resume_checkpoint}\")\n",
    "else:\n",
    "    print(\"No existing checkpoint found — starting fresh training.\")\n",
    "\n",
    "# Else start training\n",
    "peft_trainer.train(resume_from_checkpoint=resume_checkpoint)\n",
    "\n",
    "# Save the final model with training logs\n",
    "print(f\"Saving LoRA fine-tuned model to {OUTPUT_DIR}\")\n",
    "lora_model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "peft_trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62692ec",
   "metadata": {},
   "source": [
    "# Models Testing and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08d382eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded t5-small on device: cuda\n",
      "Loaded ./QA-LoRA-v1 on device: cuda\n",
      "Loaded ./QA-LoRA-v2 on device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Now we can test and compare the models on the same example\n",
    "def load_model_for_inference(directory, device=DEVICE):\n",
    "    if directory==BASE_MODEL:\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(directory)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(directory)\n",
    "    else:\n",
    "        config = PeftConfig.from_pretrained(directory)\n",
    "        base_model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path)\n",
    "        model = PeftModel.from_pretrained(base_model, directory)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "    model = model.to(device)\n",
    "    model.eval()  # ensure inference mode\n",
    "    print(f\"Loaded {directory} on device: {device}\")\n",
    "    return model, tokenizer\n",
    "\n",
    "# function to generate outputs\n",
    "def generate_output(text_input, model, tokenizer, device=DEVICE):\n",
    "    # generate input\n",
    "    inputs = tokenizer(text_input, return_tensors=\"pt\").to(device)\n",
    "    # then generate output\n",
    "    with torch.inference_mode():\n",
    "        output = tokenizer.decode(\n",
    "        model.generate(**inputs, max_new_tokens=MAX_TARGET_LENGTH)[0],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    return output\n",
    "\n",
    "t5_small, t5s_tokenizer = load_model_for_inference(BASE_MODEL)\n",
    "lora_v1, lv1_tokenizer = load_model_for_inference(\"./QA-LoRA-v1\")\n",
    "lora_v2, lv2_tokenizer = load_model_for_inference(\"./QA-LoRA-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25968d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "Question: Who are the characters in this story? \n",
      "Story: Once upon a time, in a big forest, there lived a little girl named Lily. She loved to play with her toys and equipment. One day, she found a rare, shiny stone while playing outside.\n",
      "Lily showed the stone to her friend, Tom. \"Guess what I found!\" she said. \"Wow, that's a rare stone!\" Tom replied. They were both very happy and excited.\n",
      "Together, they decided to make a special place for the rare stone. They used their equipment to dig a small hole and put the stone inside. They covered it with leaves and branches. Lily and Tom promised to always remember where their rare stone was hidden. And they played and laughed together, having lots of fun in the big forest.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Expected summary:\n",
      "Lily, Tom\n",
      "----------------------------------------------------------------------------------------------------\n",
      "t5_small Output summary:\n",
      "Lily and Tom were both very happy and excited.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lora_v1 Output summary:\n",
      "Lily and Tom\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lora_v2 Output summary:\n",
      "Lily, Tom\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display summaries\n",
    "print(\"-\" * 100)\n",
    "print(\"Actual Text:\")\n",
    "print(story)\n",
    "print(\"-\" * 100)\n",
    "print(\"Expected summary:\")  \n",
    "print(answer)\n",
    "print(\"-\" * 100)\n",
    "print(\"t5_small Output summary:\")\n",
    "print(generate_output(story, t5_small, t5s_tokenizer))\n",
    "print(\"-\" * 100)\n",
    "print(\"lora_v1 Output summary:\")\n",
    "print(generate_output(story, lora_v1, lv1_tokenizer))\n",
    "print(\"-\" * 100)\n",
    "print(\"lora_v2 Output summary:\")\n",
    "print(generate_output(story, lora_v2, lv2_tokenizer))\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3d49653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# prepare the eval dataset to be used for rouge evaluation\n",
    "original_summaries = []\n",
    "base_model_predictions = []\n",
    "lora1_model_predictions = []\n",
    "lora2_model_predictions = []\n",
    "\n",
    "print(\"Generating predictions...\")\n",
    "for item in dataset['test']:    # replace test_subset with eval_data\n",
    "    # original summary list\n",
    "    original_summaries.append(item[\"response\"])\n",
    "    # predictions\n",
    "    base1_output = generate_output(item[\"instruction\"], t5_small, t5s_tokenizer)\n",
    "    base_model_predictions.append(base1_output)\n",
    "    lora1_output = generate_output(item[\"instruction\"], lora_v1, lv1_tokenizer)\n",
    "    lora1_model_predictions.append(lora1_output)\n",
    "    lora2_output = generate_output(item[\"instruction\"], lora_v2, lv2_tokenizer)\n",
    "    lora2_model_predictions.append(lora2_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aee136d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original answer</th>\n",
       "      <th>Base Model Prediction</th>\n",
       "      <th>LoRA-v1 Model Prediction</th>\n",
       "      <th>LoRA-v2 Model Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Max and the Shiny Magnet</td>\n",
       "      <td>Max and Sam watched the boat with the shiny ma...</td>\n",
       "      <td>shiny</td>\n",
       "      <td>a hairy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom, Tom's mom</td>\n",
       "      <td>Tom and his mom made a great sandwich together...</td>\n",
       "      <td>Tom's mom</td>\n",
       "      <td>Tom's mom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tim and the Orange</td>\n",
       "      <td>Tim had a red ball that he loved to play with....</td>\n",
       "      <td>Tim</td>\n",
       "      <td>Tim's Orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Lesson of the Shiny Diamond</td>\n",
       "      <td>Bob's diamond was a red bird. Tom wanted a shi...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>Bob the Green Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tim and the Big Bag of Popcorn</td>\n",
       "      <td>Tim loved popcorn. Tim forgot his promise to s...</td>\n",
       "      <td>Tim</td>\n",
       "      <td>Tim's Big Bag of Popcorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tom's home, the tree</td>\n",
       "      <td>Tom and his friends saved the cat. They were a...</td>\n",
       "      <td>a tree</td>\n",
       "      <td>a tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Izzy and Tommy's Careful Play</td>\n",
       "      <td>Izzy was very careful when she played because ...</td>\n",
       "      <td>Izzy</td>\n",
       "      <td>Izzy and Tommy's Big Garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tim and the Whistle Dogs</td>\n",
       "      <td>Tim was surprised and happy. Now, he had many ...</td>\n",
       "      <td>Tim</td>\n",
       "      <td>Tim's Dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Compassionate Goose</td>\n",
       "      <td>Goose: What is a good title for this story?</td>\n",
       "      <td>Goose</td>\n",
       "      <td>The Goose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sue, Tim</td>\n",
       "      <td>Sue was very happy with her blocks. Tim was we...</td>\n",
       "      <td>Sue</td>\n",
       "      <td>Sue, Tim, Tim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Original answer  \\\n",
       "0         Max and the Shiny Magnet   \n",
       "1                   Tom, Tom's mom   \n",
       "2               Tim and the Orange   \n",
       "3  The Lesson of the Shiny Diamond   \n",
       "4   Tim and the Big Bag of Popcorn   \n",
       "5             Tom's home, the tree   \n",
       "6    Izzy and Tommy's Careful Play   \n",
       "7         Tim and the Whistle Dogs   \n",
       "8          The Compassionate Goose   \n",
       "9                         Sue, Tim   \n",
       "\n",
       "                               Base Model Prediction LoRA-v1 Model Prediction  \\\n",
       "0  Max and Sam watched the boat with the shiny ma...                    shiny   \n",
       "1  Tom and his mom made a great sandwich together...                Tom's mom   \n",
       "2  Tim had a red ball that he loved to play with....                      Tim   \n",
       "3  Bob's diamond was a red bird. Tom wanted a shi...                      Bob   \n",
       "4  Tim loved popcorn. Tim forgot his promise to s...                      Tim   \n",
       "5  Tom and his friends saved the cat. They were a...                   a tree   \n",
       "6  Izzy was very careful when she played because ...                     Izzy   \n",
       "7  Tim was surprised and happy. Now, he had many ...                      Tim   \n",
       "8        Goose: What is a good title for this story?                    Goose   \n",
       "9  Sue was very happy with her blocks. Tim was we...                      Sue   \n",
       "\n",
       "      LoRA-v2 Model Prediction  \n",
       "0                  a hairy dog  \n",
       "1                    Tom's mom  \n",
       "2                 Tim's Orange  \n",
       "3           Bob the Green Bird  \n",
       "4     Tim's Big Bag of Popcorn  \n",
       "5                       a tree  \n",
       "6  Izzy and Tommy's Big Garden  \n",
       "7                    Tim's Dog  \n",
       "8                    The Goose  \n",
       "9                Sue, Tim, Tim  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine into dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"Original answer\": original_summaries,\n",
    "    \"Base Model Prediction\": base_model_predictions,\n",
    "    \"LoRA-v1 Model Prediction\": lora1_model_predictions,\n",
    "    \"LoRA-v2 Model Prediction\": lora2_model_predictions\n",
    "})\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60a64a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform ROUGE evaluation\n",
    "def compute_rouge_score(predictions, references):\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    results = rouge.compute(\n",
    "        predictions=predictions, \n",
    "        references=references,\n",
    "        use_aggregator=True,\n",
    "        use_stemmer=True,\n",
    "    )\n",
    "    return results\n",
    "\n",
    "# Clean text for fair comparison\n",
    "original_summaries = [s.strip().lower() for s in original_summaries]\n",
    "base_model_predictions = [p.strip().lower() for p in base_model_predictions]\n",
    "lora_model1_predictions = [p.strip().lower() for p in lora1_model_predictions]\n",
    "lora_model2_predictions = [p.strip().lower() for p in lora2_model_predictions]\n",
    "\n",
    "# Compute ROUGE scores\n",
    "base_model_results = compute_rouge_score(base_model_predictions, original_summaries)\n",
    "lora1_model_results = compute_rouge_score(lora1_model_predictions, original_summaries)\n",
    "lora2_model_results = compute_rouge_score(lora2_model_predictions, original_summaries)\n",
    "all_results = {\n",
    "    \"t5-small Model\": base_model_results,\n",
    "    \"LoRA-v1 Model\": lora1_model_results,\n",
    "    \"LoRA-v2 Model\": lora2_model_results,\n",
    "}\n",
    "\n",
    "# Compare relative percentage differences in rouge scores over base model\n",
    "def display_percentage_difference(base_results, new_results, model_name):\n",
    "    print(f\"Relative Percentage Differences in ROUGE scores for {model_name} over Base Model:\")\n",
    "    for key in base_results.keys():\n",
    "        base_score = base_results[key] * 100  # convert to percentage\n",
    "        new_score = new_results[key] * 100  # convert to percentage\n",
    "        relative_diff = ((new_score - base_score) / base_score) * 100\n",
    "        print(f\"{key}: {relative_diff:.2f}%\")\n",
    "    print(dashline)\n",
    "\n",
    "#display_percentage_difference(base_model_results, lora1_model_results, \"flan-T5 Model\")\n",
    "#display_percentage_difference(base_model_results, lora2_model_results, \"LoRA-v2 Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "492217ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE scores for various models' answer against ground truth:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t5-small Model</th>\n",
       "      <td>0.179773</td>\n",
       "      <td>0.032921</td>\n",
       "      <td>0.170074</td>\n",
       "      <td>0.170642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA-v1 Model</th>\n",
       "      <td>0.457033</td>\n",
       "      <td>0.076098</td>\n",
       "      <td>0.447999</td>\n",
       "      <td>0.449476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA-v2 Model</th>\n",
       "      <td>0.621968</td>\n",
       "      <td>0.363206</td>\n",
       "      <td>0.621053</td>\n",
       "      <td>0.623734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rouge1    rouge2    rougeL  rougeLsum\n",
       "t5-small Model  0.179773  0.032921  0.170074   0.170642\n",
       "LoRA-v1 Model   0.457033  0.076098  0.447999   0.449476\n",
       "LoRA-v2 Model   0.621968  0.363206  0.621053   0.623734"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ROUGE scores for various models' answer against ground truth:\")\n",
    "results_df = pd.DataFrame.from_dict(all_results, orient='index')\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fdef458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot visuals\n",
    "keys = list(base_model_results.keys())\n",
    "base_vals = [base_model_results[k] * 100 for k in keys]\n",
    "lora1_vals = [lora1_model_results[k] * 100 for k in keys]\n",
    "lora2_vals = [lora2_model_results[k] * 100 for k in keys]\n",
    "\n",
    "x = np.arange(len(keys))  # the label locations\n",
    "width = 0.22              # width of each bar\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.bar(x - width, base_vals, width, label='Base T5-small')\n",
    "plt.bar(x , lora1_vals, width, label='LoRA Fine-Tuned v1')\n",
    "plt.bar(x + width, lora2_vals, width, label='LoRA Fine-Tuned v2')\n",
    "\n",
    "plt.xticks(x, keys)\n",
    "plt.title('ROUGE Score Comparison for Characters/Settings/StoryTitle')\n",
    "plt.ylabel('Score (%)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82d8d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to normalise prediction answers\n",
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"Lowercase, remove punctuation, extra spaces.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # remove punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text)     # remove extra whitespace\n",
    "    return text.strip()\n",
    "\n",
    "# custom f1_score calculator\n",
    "def f1_score_list(prediction: str, reference: str) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Computes token/item-level F1 between prediction and reference.\n",
    "    Returns: (precision, recall, f1)\n",
    "    \"\"\"\n",
    "    # Normalize and split by comma\n",
    "    pred_items = [normalize_text(x) for x in prediction.split(\",\")]\n",
    "    ref_items = [normalize_text(x) for x in reference.split(\",\")]\n",
    "\n",
    "    # Convert to sets for matching\n",
    "    pred_set = set(pred_items)\n",
    "    ref_set = set(ref_items)\n",
    "\n",
    "    # Compute precision, recall\n",
    "    if len(pred_set) == 0 or len(ref_set) == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "\n",
    "    true_positives = len(pred_set & ref_set)\n",
    "    precision = true_positives / len(pred_set)\n",
    "    recall = true_positives / len(ref_set)\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        f1 = 0.0\n",
    "    else:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26c27cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-scores for predicted answers against ground truth:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Base T5-small Model</th>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA-v1 Model</th>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.0815</td>\n",
       "      <td>0.1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA-v2 Model</th>\n",
       "      <td>0.3907</td>\n",
       "      <td>0.3611</td>\n",
       "      <td>0.3678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    precision  recall      f1\n",
       "Base T5-small Model    0.0074  0.0083  0.0076\n",
       "LoRA-v1 Model          0.1556  0.0815  0.1037\n",
       "LoRA-v2 Model          0.3907  0.3611  0.3678"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate using f1-score since Characters and Settings are list of elements\n",
    "# the scores are not reflective of overall data since Title generally has 0 f1-score\n",
    "\n",
    "def evaluate_dataset(predictions: List[str], references: List[str]):\n",
    "    \"\"\"\n",
    "    Evaluates lists of predictions and references.\n",
    "    Returns average precision, recall, F1.\n",
    "    \"\"\"\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        p, r, f1 = f1_score_list(pred, ref)\n",
    "        precisions.append(p)\n",
    "        recalls.append(r)\n",
    "        f1s.append(f1)\n",
    "\n",
    "    avg_precision = sum(precisions) / len(precisions)\n",
    "    avg_recall = sum(recalls) / len(recalls)\n",
    "    avg_f1 = sum(f1s) / len(f1s)\n",
    "\n",
    "    return {\"precision\": f\"{avg_precision:.4f}\", \"recall\": f\"{avg_recall:.4f}\", \"f1\": f\"{avg_f1:.4f}\"}\n",
    "\n",
    "\n",
    "base_f1_results = evaluate_dataset(base_model_predictions, original_summaries)\n",
    "lorav1_f1_results = evaluate_dataset(lora_model1_predictions, original_summaries)\n",
    "lorav2_f1_results = evaluate_dataset(lora_model2_predictions, original_summaries)\n",
    "all_f1results = {\n",
    "    \"Base T5-small Model\": base_f1_results,\n",
    "    \"LoRA-v1 Model\": lorav1_f1_results,\n",
    "    \"LoRA-v2 Model\": lorav2_f1_results\n",
    "}\n",
    "# Display results\n",
    "print(\"F1-scores for predicted answers against ground truth:\")\n",
    "df2 = pd.DataFrame.from_dict(all_f1results, orient='index')\n",
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
