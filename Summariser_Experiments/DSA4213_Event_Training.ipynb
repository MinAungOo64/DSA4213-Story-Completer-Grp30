{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5a40adb",
   "metadata": {},
   "source": [
    "# Finetuning model for Event summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46e62adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to d:\\Keven(Work)\\dsa4213\\final\n",
      "[nltk_data]     project\\venv\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     d:\\Keven(Work)\\dsa4213\\final project\\venv\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     d:\\Keven(Work)\\dsa4213\\final project\\venv\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n",
    "from bert_score import score\n",
    "import evaluate\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Make sure the required NLTK data packages are available\n",
    "# Dynamically construct NLTK data directory relative to current working directory\n",
    "nltk_data_dir = os.path.join(os.getcwd(), \"venv\", \"nltk_data\")\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(nltk_data_dir, exist_ok=True)\n",
    "\n",
    "nltk.download(\"punkt\", download_dir=nltk_data_dir)\n",
    "nltk.download('punkt_tab', download_dir=nltk_data_dir)\n",
    "nltk.download(\"stopwords\", download_dir=nltk_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3e9e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "def set_seed(seed=4213):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(4213)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf5599fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "# ==============================\n",
    "TRAIN_FILE = \"stories_with_outlines_first3000.jsonl\"\n",
    "OUTPUT_DIR = \"./Event-summariser-LoRA-v3\"\n",
    "BASE_MODEL = \"t5-small\"\n",
    "BASE_MODEL2 = \"google/flan-t5-base\"\n",
    "USE_LORA = True\n",
    "MAX_INPUT_LENGTH = 256\n",
    "MAX_TARGET_LENGTH = 128\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8685930",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c574d19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading each event dataset: stories_with_outlines_first3000.jsonl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Summarize this text:\\nOnce upon a time, in a warm and sunny place, there was a big pit. A little boy named Tom liked to play near the pit.',\n",
       "  'response': 'Tom enjoys playing near a big pit in a sunny location.'},\n",
       " {'instruction': 'Summarize this text:\\nOne day, Tom lost his red ball. He was very sad.',\n",
       "  'response': 'Tom loses his red ball and feels very sad about it.'},\n",
       " {'instruction': 'Summarize this text:\\nTom asked his friend, Sam, to help him search for the ball. They looked high and low, but they could not find the ball.',\n",
       "  'response': 'Tom asks his friend Sam for help, and they search for the ball without success.'},\n",
       " {'instruction': 'Summarize this text:\\nTom said, \"I think my ball fell into the pit.\" Sam and Tom went close to the pit. They were scared, but they wanted to find the red ball.',\n",
       "  'response': 'Tom suspects the ball fell into the pit, and he and Sam approach it despite their fear.'},\n",
       " {'instruction': 'Summarize this text:\\nThey looked into the pit, but it was too dark to see. Tom said, \"We must go in and search for my ball.\"',\n",
       "  'response': 'Determined to find the ball, Tom and Sam decide to go into the dark pit.'},\n",
       " {'instruction': 'Summarize this text:\\nThey went into the pit to search. It was dark and scary. They could not find the ball.',\n",
       "  'response': 'Inside the pit, they search but cannot find the ball and realize they are stuck.'},\n",
       " {'instruction': 'Summarize this text:\\nThey tried to get out, but the pit was too deep. Tom and Sam were stuck in the pit.',\n",
       "  'response': 'Tom and Sam call for help, but no one hears them, leaving them sad and scared.'},\n",
       " {'instruction': 'Summarize this text:\\nTom and Lily were playing with their toys in the living room. They liked to build towers and bridges with their blocks and cars.',\n",
       "  'response': 'Tom and Lily play with their toys, building towers and bridges.'},\n",
       " {'instruction': 'Summarize this text:\\nTom was very proud of his tall tower. He wanted to make it even taller, so he reached for more blocks. \"Tom, can I have some blocks too?\" Lily asked. She wanted to make a bridge for her cars. \"No, these are mine. Go find your own,\" Tom said. He did not want to share with his sister.',\n",
       "  'response': 'Tom is proud of his tall tower and refuses to share blocks with Lily.'},\n",
       " {'instruction': 'Summarize this text:\\nHe pulled the blocks closer to him. Lily felt sad and angry. She did not think Tom was being nice. She looked at his tower and had an idea.',\n",
       "  'response': \"Lily feels sad and angry, then decides to pull a block from Tom's tower.\"}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in raw data\n",
    "\n",
    "print(f\"Loading each event dataset: {TRAIN_FILE}\")\n",
    "# Read all lines as JSON\n",
    "raw_data = []\n",
    "with open(TRAIN_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        each_line = json.loads(line)\n",
    "        # extract story text and reformat into a list of lines\n",
    "        story = each_line['story']\n",
    "        lines_of_story = sent_tokenize(story)\n",
    "        # extract outline details: events\n",
    "        outline = each_line['outline']\n",
    "        events = outline.get('events', [])\n",
    "        full_summary = \"\"\n",
    "        for key, value in events.items():\n",
    "            event_summary = value.get('summary')\n",
    "            # Now we want to slice the stories based on 'from_lines'\n",
    "            from_lines = value.get('from_lines', [])\n",
    "            start_idx = from_lines[0] - 1  # Convert to 0-based index\n",
    "            end_idx = from_lines[-1]  # Inclusive end index\n",
    "            event_text = \" \".join(lines_of_story[start_idx:end_idx])\n",
    "            # For each event_text, prepend the prompt\n",
    "            prompt = \"Summarize this text:\\n\" \n",
    "            final_input = prompt + event_text #+ \"\\nSummary:\"\n",
    "\n",
    "            # append to dataset\n",
    "            raw_data.append({\"instruction\": final_input, \"response\": event_summary})\n",
    "\n",
    "raw_data[:10]  # preview first 10 entries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06ff040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'response'],\n",
       "        num_rows: 16592\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'response'],\n",
       "        num_rows: 168\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_list(raw_data)\n",
    "dataset = dataset.train_test_split(test_size=0.01)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceb8c9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model: t5-small\n"
     ]
    }
   ],
   "source": [
    "# Prepare tokenizer and model\n",
    "print(f\"Loading base model: {BASE_MODEL}\")\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(BASE_MODEL).to(DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07e91174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing dataset: 100%|██████████| 16592/16592 [00:11<00:00, 1468.10 examples/s]\n",
      "Tokenizing dataset: 100%|██████████| 168/168 [00:00<00:00, 1435.91 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_function(batch):\n",
    "    model_inputs = tokenizer(\n",
    "        batch[\"instruction\"],\n",
    "        max_length=MAX_INPUT_LENGTH,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        text_target=batch[\"response\"],\n",
    "        max_length=MAX_TARGET_LENGTH,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        )  \n",
    "    # Replace pad token IDs with -100 so they’re ignored in cross-entropy loss\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(token if token != tokenizer.pad_token_id else -100) for token in label]\n",
    "        for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_dataset = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"instruction\", \"response\"],\n",
    "    desc=\"Tokenizing dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2334851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Event:\n",
      "Summarize this text:\n",
      "Once upon a time, in a big town, there was a lot of traffic. Cars, buses, and bikes went up and down the roads all day. People were always in a hurry, and they did not look around. They were ignorant of the nice things around them.\n",
      "--------------------------------------------------------------------------------\n",
      "Expected summary:\n",
      "In a bustling town filled with traffic, people hurriedly moved about, often ignoring their surroundings.\n",
      "--------------------------------------------------------------------------------\n",
      "Model Output summary:\n",
      "False\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test current model with zero shot inference\n",
    "from torch import no_grad\n",
    "\n",
    "# use one example from test set\n",
    "event = dataset['test'][67][\"instruction\"]\n",
    "summary = dataset['test'][67][\"response\"]\n",
    "\n",
    "# Tokenise input\n",
    "inputs = tokenizer(event, return_tensors=\"pt\", max_length=MAX_INPUT_LENGTH, truncation=True).to(DEVICE)\n",
    "# Generate output and decode\n",
    "with no_grad():\n",
    "    outputs = base_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=MAX_TARGET_LENGTH,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "base_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "dashline = \"-\" * 80\n",
    "print(dashline)\n",
    "print(\"Event:\")\n",
    "print(event)\n",
    "print(dashline)\n",
    "print(\"Expected summary:\")  \n",
    "print(summary)\n",
    "print(dashline)\n",
    "print(\"Model Output summary:\")\n",
    "print(base_output)\n",
    "print(dashline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0328e9da",
   "metadata": {},
   "source": [
    "# PEFT model using LoRA\n",
    "(skip the cells in this section if not finetuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "500ec677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LoRA adapter for lightweight fine-tuning...\n",
      "trainable params: 294,912 || all params: 60,801,536 || trainable%: 0.4850\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# LoRA configuration\n",
    "if USE_LORA:\n",
    "    print(\"Applying LoRA adapter for lightweight fine-tuning...\")\n",
    "    lora_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=32,\n",
    "        target_modules=[\"q\", \"v\"],\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"SEQ_2_SEQ_LM\",\n",
    "    )\n",
    "lora_model = get_peft_model(base_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "lora_model = lora_model.to(DEVICE)\n",
    "\n",
    "# PEFT Training configuration\n",
    "peft_training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    auto_find_batch_size=True,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=3e-5,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    predict_with_generate=True,\n",
    "    report_to=\"none\",  # disable wandb/tensorboard\n",
    "    save_strategy=\"steps\",  \n",
    "    save_steps=50,          \n",
    "    save_total_limit=3,     \n",
    "    logging_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=lora_model\n",
    ")\n",
    "\n",
    "# PEFT Trainer setup\n",
    "peft_trainer = Trainer(  \n",
    "    model=lora_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66b87494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "No existing checkpoint found — starting fresh training.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1557' max='1557' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1557/1557 09:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>519</td>\n",
       "      <td>2.723300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1038</td>\n",
       "      <td>2.382100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1557</td>\n",
       "      <td>2.317900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving LoRA fine-tuned model to ./Event-summariser-LoRA-v2\n"
     ]
    }
   ],
   "source": [
    "# Initiate training\n",
    "\n",
    "print(\"Starting training...\")\n",
    "# Resume only if checkpoint exists\n",
    "resume_checkpoint = None\n",
    "last_checkpoint_dir = os.path.join(OUTPUT_DIR, \"checkpoint-last\")\n",
    "if os.path.isdir(last_checkpoint_dir):\n",
    "    resume_checkpoint = last_checkpoint_dir\n",
    "    print(f\"Resuming from checkpoint: {resume_checkpoint}\")\n",
    "else:\n",
    "    print(\"No existing checkpoint found — starting fresh training.\")\n",
    "\n",
    "# Else start training\n",
    "peft_trainer.train(resume_from_checkpoint=resume_checkpoint)\n",
    "\n",
    "# Save the final model with training logs\n",
    "print(f\"Saving LoRA fine-tuned model to {OUTPUT_DIR}\")\n",
    "lora_model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "peft_trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e10ee63",
   "metadata": {},
   "source": [
    "# Models Testing and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71ad3b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded t5-small on device: cuda\n",
      "Loaded google/flan-t5-base on device: cuda\n",
      "Loaded ./Event-summariser-LoRA-v1 on device: cuda\n",
      "Loaded ./Event-summariser-LoRA-v2 on device: cuda\n",
      "Loaded ./Event-summariser-LoRA-v3 on device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Now we can test and compare the models on the same example\n",
    "def load_model_for_inference(directory, device=DEVICE):\n",
    "    if directory==BASE_MODEL or BASE_MODEL2:\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(directory)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(directory)\n",
    "    else:\n",
    "        config = PeftConfig.from_pretrained(directory)\n",
    "        base_model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path)\n",
    "        model = PeftModel.from_pretrained(base_model, directory)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "    model = model.to(device)\n",
    "    model.eval()  # ensure inference mode\n",
    "    print(f\"Loaded {directory} on device: {device}\")\n",
    "    return model, tokenizer\n",
    "\n",
    "# function to generate outputs\n",
    "def generate_output(text_input, model, tokenizer, device=DEVICE):\n",
    "    # generate input\n",
    "    inputs = tokenizer(text_input, return_tensors=\"pt\").to(device)\n",
    "    # then generate output\n",
    "    with torch.inference_mode():\n",
    "        output = tokenizer.decode(\n",
    "        model.generate(**inputs, max_new_tokens=MAX_TARGET_LENGTH)[0],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    return output\n",
    "\n",
    "t5_small, t5s_tokenizer = load_model_for_inference(BASE_MODEL)\n",
    "flan_t5, ft5_tokenizer = load_model_for_inference(BASE_MODEL2)\n",
    "lora_v1, lv1_tokenizer = load_model_for_inference(\"./Event-summariser-LoRA-v1\")\n",
    "lora_v2, lv2_tokenizer = load_model_for_inference(\"./Event-summariser-LoRA-v2\")\n",
    "lora_v3, lv3_tokenizer = load_model_for_inference(\"./Event-summariser-LoRA-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59422356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Actual Text:\n",
      "Summarize this text:\n",
      "Once upon a time, in a big town, there was a lot of traffic. Cars, buses, and bikes went up and down the roads all day. People were always in a hurry, and they did not look around. They were ignorant of the nice things around them.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Expected summary:\n",
      "In a bustling town filled with traffic, people hurriedly moved about, often ignoring their surroundings.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "t5_small Output summary:\n",
      "True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "flan_t5 Output summary:\n",
      "The traffic was very bad.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lora_v1 Output summary:\n",
      "In a big town, there was a lot of traffic, and people were always in a hurry, and they were ignorant of the nice things around them.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lora_v2 Output summary:\n",
      "In a big town, people were always in a hurry, and they were ignorant of the nice things around them.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lora_v3 Output summary:\n",
      "The traffic was very bad.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display summaries\n",
    "print(\"-\" * 100)\n",
    "print(\"Actual Text:\")\n",
    "print(event)\n",
    "print(\"-\" * 100)\n",
    "print(\"Expected summary:\")  \n",
    "print(summary)\n",
    "print(\"-\" * 100)\n",
    "print(\"t5_small Output summary:\")\n",
    "print(generate_output(event, t5_small, t5s_tokenizer))\n",
    "print(\"-\" * 100)\n",
    "print(\"flan_t5 Output summary:\")\n",
    "print(generate_output(event, flan_t5, ft5_tokenizer))\n",
    "print(\"-\" * 100)\n",
    "print(\"lora_v1 Output summary:\")\n",
    "print(generate_output(event, lora_v1, lv1_tokenizer))\n",
    "print(\"-\" * 100)\n",
    "print(\"lora_v2 Output summary:\")\n",
    "print(generate_output(event, lora_v2, lv2_tokenizer))\n",
    "print(\"-\" * 100)\n",
    "print(\"lora_v3 Output summary:\")\n",
    "print(generate_output(event, lora_v3, lv3_tokenizer))\n",
    "print(\"-\" * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556bb099",
   "metadata": {},
   "source": [
    "# Evaluation using ROGUE + BERT scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f02c0bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n"
     ]
    }
   ],
   "source": [
    "# prepare the eval dataset to be used for rouge evaluation\n",
    "original_summaries = []\n",
    "base_model1_predictions = []\n",
    "base_model2_predictions = []\n",
    "lora1_model_predictions = []\n",
    "lora2_model_predictions = []\n",
    "lora3_model_predictions = []\n",
    "\n",
    "print(\"Generating predictions...\")\n",
    "for item in dataset['test']:    # replace test_subset with eval_data\n",
    "    # original summary list\n",
    "    original_summaries.append(item[\"response\"])\n",
    "    # predictions\n",
    "    base1_output = generate_output(item[\"instruction\"], t5_small, t5s_tokenizer)\n",
    "    base_model1_predictions.append(base1_output)\n",
    "    base2_output = generate_output(item[\"instruction\"], flan_t5, ft5_tokenizer)\n",
    "    base_model2_predictions.append(base2_output)\n",
    "    lora1_output = generate_output(item[\"instruction\"], lora_v1, lv1_tokenizer)\n",
    "    lora1_model_predictions.append(lora1_output)\n",
    "    lora2_output = generate_output(item[\"instruction\"], lora_v2, lv2_tokenizer)\n",
    "    lora2_model_predictions.append(lora2_output)\n",
    "    lora3_output = generate_output(item[\"instruction\"], lora_v3, lv3_tokenizer)\n",
    "    lora3_model_predictions.append(lora3_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a5fc3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Summary</th>\n",
       "      <th>t5-small Prediction</th>\n",
       "      <th>flan-t5-base Prediction</th>\n",
       "      <th>LoRA-v1 Model Prediction</th>\n",
       "      <th>LoRA-v2 Model Prediction</th>\n",
       "      <th>LoRA-v3 Model Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One friend suggests using sign language, which...</td>\n",
       "      <td>Zusammenfassen text: One of her friends sugges...</td>\n",
       "      <td>Molly was excited to try to sign to another fr...</td>\n",
       "      <td>One of her friends suggested they sign to each...</td>\n",
       "      <td>Molly, a friend of Molly, is confused but exci...</td>\n",
       "      <td>Molly was excited to try to sign to another fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After waiting for a while, the toy egg does no...</td>\n",
       "      <td>Zusammenfassen Sie diesen Text: Lucy hat sehr ...</td>\n",
       "      <td>Lucy was excited to see her friends.</td>\n",
       "      <td>Lucy is excited about the success of the proje...</td>\n",
       "      <td>Lucy and Lucy are excited about the success of...</td>\n",
       "      <td>Lucy was excited to see her friends.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lily, a little girl, wakes up in her comfortab...</td>\n",
       "      <td>Text: Let's resume this text:</td>\n",
       "      <td>Look at the bed.</td>\n",
       "      <td>Lily, a little girl, had a big, soft, comforta...</td>\n",
       "      <td>Lily, a little girl, wakes up and changes her ...</td>\n",
       "      <td>Look at the bed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They read about the aeroplane's engine and fun...</td>\n",
       "      <td>Zusammenfassend</td>\n",
       "      <td>They went to the library to read a book about ...</td>\n",
       "      <td>The two friends discover the aeroplane from th...</td>\n",
       "      <td>The two friends decided to find out more about...</td>\n",
       "      <td>They went to the library to read a book about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Despite his mom's warnings, Tom runs around ca...</td>\n",
       "      <td>False</td>\n",
       "      <td>Tom was scared of bees.</td>\n",
       "      <td>Tom did not listen to his mom when she told hi...</td>\n",
       "      <td>Tom does not look where he is going, but does ...</td>\n",
       "      <td>Tom was scared of bees.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Original Summary  ...                           LoRA-v3 Model Prediction\n",
       "0  One friend suggests using sign language, which...  ...  Molly was excited to try to sign to another fr...\n",
       "1  After waiting for a while, the toy egg does no...  ...               Lucy was excited to see her friends.\n",
       "2  Lily, a little girl, wakes up in her comfortab...  ...                                   Look at the bed.\n",
       "3  They read about the aeroplane's engine and fun...  ...  They went to the library to read a book about ...\n",
       "4  Despite his mom's warnings, Tom runs around ca...  ...                            Tom was scared of bees.\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine into dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"Original Summary\": original_summaries,\n",
    "    \"t5-small Prediction\": base_model1_predictions,\n",
    "    \"flan-t5-base Prediction\": base_model2_predictions,\n",
    "    \"LoRA-v1 Model Prediction\": lora1_model_predictions,\n",
    "    \"LoRA-v2 Model Prediction\": lora2_model_predictions,\n",
    "    \"LoRA-v3 Model Prediction\": lora3_model_predictions\n",
    "})\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc4222a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform ROUGE evaluation\n",
    "def compute_rouge_score(predictions, references):\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    results = rouge.compute(\n",
    "        predictions=predictions, \n",
    "        references=references,\n",
    "        use_aggregator=True,\n",
    "        use_stemmer=True,\n",
    "    )\n",
    "    return results\n",
    "\n",
    "# Clean text for fair comparison\n",
    "original_summaries = [s.strip().lower() for s in original_summaries]\n",
    "base_model1_predictions = [p.strip().lower() for p in base_model1_predictions]\n",
    "base_model2_predictions = [p.strip().lower() for p in base_model2_predictions]\n",
    "lora_model1_predictions = [p.strip().lower() for p in lora1_model_predictions]\n",
    "lora_model2_predictions = [p.strip().lower() for p in lora2_model_predictions]\n",
    "lora_model3_predictions = [p.strip().lower() for p in lora3_model_predictions]\n",
    "\n",
    "# Compute ROUGE scores\n",
    "base_model1_results = compute_rouge_score(base_model1_predictions, original_summaries)\n",
    "base_model2_results = compute_rouge_score(base_model2_predictions, original_summaries)\n",
    "lora1_model_results = compute_rouge_score(lora1_model_predictions, original_summaries)\n",
    "lora2_model_results = compute_rouge_score(lora2_model_predictions, original_summaries)\n",
    "lora3_model_results = compute_rouge_score(lora3_model_predictions, original_summaries)\n",
    "\n",
    "all_results = {\n",
    "    \"t5-small Model\": base_model1_results,\n",
    "    \"flan-t5-base Model\": base_model2_results,\n",
    "    \"LoRA-v1 Model\": lora1_model_results,\n",
    "    \"LoRA-v2 Model\": lora2_model_results,\n",
    "    \"LoRA-v3 Model\": lora3_model_results\n",
    "}\n",
    "\n",
    "\n",
    "# Compare relative percentage differences in rouge scores over base model\n",
    "def display_percentage_difference(base_results, new_results, model_name):\n",
    "    print(f\"Relative Percentage Differences in ROUGE scores for {model_name} over Base Model:\")\n",
    "    for key in base_results.keys():\n",
    "        base_score = base_results[key] * 100  # convert to percentage\n",
    "        new_score = new_results[key] * 100  # convert to percentage\n",
    "        relative_diff = ((new_score - base_score) / base_score) * 100\n",
    "        print(f\"{key}: {relative_diff:.2f}%\")\n",
    "    print(dashline)\n",
    "\n",
    "#display_percentage_difference(base_model_results, lora1_model_results, \"LoRA-v1 Model\")\n",
    "#display_percentage_difference(base_model_results, lora2_model_results, \"LoRA-v2 Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3e938ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE scores for various models against ground truth summaries:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t5-small Model</th>\n",
       "      <td>0.151451</td>\n",
       "      <td>0.066716</td>\n",
       "      <td>0.128294</td>\n",
       "      <td>0.128367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan-t5-base Model</th>\n",
       "      <td>0.251915</td>\n",
       "      <td>0.066191</td>\n",
       "      <td>0.216323</td>\n",
       "      <td>0.216722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA-v1 Model</th>\n",
       "      <td>0.476206</td>\n",
       "      <td>0.247403</td>\n",
       "      <td>0.411782</td>\n",
       "      <td>0.411357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA-v2 Model</th>\n",
       "      <td>0.447332</td>\n",
       "      <td>0.218330</td>\n",
       "      <td>0.391013</td>\n",
       "      <td>0.392638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA-v3 Model</th>\n",
       "      <td>0.251915</td>\n",
       "      <td>0.066191</td>\n",
       "      <td>0.216323</td>\n",
       "      <td>0.216722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      rouge1    rouge2    rougeL  rougeLsum\n",
       "t5-small Model      0.151451  0.066716  0.128294   0.128367\n",
       "flan-t5-base Model  0.251915  0.066191  0.216323   0.216722\n",
       "LoRA-v1 Model       0.476206  0.247403  0.411782   0.411357\n",
       "LoRA-v2 Model       0.447332  0.218330  0.391013   0.392638\n",
       "LoRA-v3 Model       0.251915  0.066191  0.216323   0.216722"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ROUGE scores for various models against ground truth summaries:\")\n",
    "results_df = pd.DataFrame.from_dict(all_results, orient='index')\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3798a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot visuals\n",
    "keys = list(base_model1_results.keys())\n",
    "base1_vals = [base_model1_results[k] * 100 for k in keys]\n",
    "base2_vals = [base_model2_results[k] * 100 for k in keys]\n",
    "lora1_vals = [lora1_model_results[k] * 100 for k in keys]\n",
    "lora2_vals = [lora2_model_results[k] * 100 for k in keys]\n",
    "lora3_vals = [lora3_model_results[k] * 100 for k in keys]\n",
    "\n",
    "x = np.arange(len(keys))  # the label locations\n",
    "width = 0.17             # width of each bar\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.bar(x - width*2, base1_vals, width, label='Base T5-small')\n",
    "plt.bar(x - width, base2_vals, width, label='Flan-T5-base')\n",
    "plt.bar(x , lora1_vals, width, label='LoRA Fine-Tuned v1')\n",
    "plt.bar(x + width, lora2_vals, width, label='LoRA Fine-Tuned v2')\n",
    "plt.bar(x + width*2, lora3_vals, width, label='LoRA Fine-Tuned v3')\n",
    "\n",
    "plt.xticks(x, keys)\n",
    "plt.title('ROUGE Score Comparison')\n",
    "plt.ylabel('Score (%)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4caf463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:35<00:00,  7.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 17.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 36.06 seconds, 4.66 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:18<00:00,  3.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 35.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 18.26 seconds, 9.20 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:20<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 56.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 20.35 seconds, 8.26 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:19<00:00,  3.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 56.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 20.04 seconds, 8.38 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:16<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 56.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 16.55 seconds, 10.15 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Now evaluate using BERT score\n",
    "def compute_bert_score(predictions, references):\n",
    "    P, R, F1 = score(predictions, references, model_type=\"roberta-large\" ,lang=\"en\", verbose=True)\n",
    "    return {\n",
    "        \"precision\": P.mean().item(),\n",
    "        \"recall\": R.mean().item(),\n",
    "        \"f1\": F1.mean().item()\n",
    "    }\n",
    "\n",
    "base_model1_bert = compute_bert_score(base_model1_predictions, original_summaries)\n",
    "base_model2_bert = compute_bert_score(base_model2_predictions, original_summaries)\n",
    "lora1_model_bert = compute_bert_score(lora1_model_predictions, original_summaries)\n",
    "lora2_model_bert = compute_bert_score(lora2_model_predictions, original_summaries)\n",
    "lora3_model_bert = compute_bert_score(lora3_model_predictions, original_summaries)\n",
    "\n",
    "all_berts = {\n",
    "    \"t5-small Model\": base_model1_bert,\n",
    "    \"flan-t5-base Model\": base_model2_bert,\n",
    "    \"LoRA-v1 Model\": lora1_model_bert,\n",
    "    \"LoRA-v2 Model\": lora2_model_bert,\n",
    "    \"LoRA-v3 Model\": lora3_model_bert\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62e177ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT scores for predictions against actual summaries:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t5-small Model</th>\n",
       "      <td>0.830578</td>\n",
       "      <td>0.851901</td>\n",
       "      <td>0.839987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flan-t5-base Model</th>\n",
       "      <td>0.906498</td>\n",
       "      <td>0.869756</td>\n",
       "      <td>0.887633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA-v1 Model</th>\n",
       "      <td>0.918053</td>\n",
       "      <td>0.916870</td>\n",
       "      <td>0.917388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA-v2 Model</th>\n",
       "      <td>0.916540</td>\n",
       "      <td>0.907566</td>\n",
       "      <td>0.911930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA-v3 Model</th>\n",
       "      <td>0.906498</td>\n",
       "      <td>0.869756</td>\n",
       "      <td>0.887633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    precision    recall        f1\n",
       "t5-small Model       0.830578  0.851901  0.839987\n",
       "flan-t5-base Model   0.906498  0.869756  0.887633\n",
       "LoRA-v1 Model        0.918053  0.916870  0.917388\n",
       "LoRA-v2 Model        0.916540  0.907566  0.911930\n",
       "LoRA-v3 Model        0.906498  0.869756  0.887633"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"BERT scores for predictions against actual summaries:\")\n",
    "bert_df = pd.DataFrame.from_dict(all_berts, orient='index')\n",
    "bert_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
